{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#* Import the code needed\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#* Define paths\n",
    "directory_path = Path('../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_excel(\n",
    "    directory_path / 'data' / 'regression_data' / 'Population' / 'regression_Population.xlsx',\n",
    "    index_col=0)\n",
    "\n",
    "PpD = pd.read_excel(\n",
    "    directory_path / 'data' / 'regression_data' / 'PpD' / 'regression_PpD.xlsx',\n",
    "    index_col=0)\n",
    "\n",
    "UFApD = pd.read_excel(\n",
    "    directory_path / 'data' / 'regression_data' / 'UFApD' / 'regression_UFApD.xlsx',\n",
    "    index_col=0)\n",
    "\n",
    "energy_intensity = pd.read_excel(\n",
    "    directory_path / 'data' / 'cleaned_and_combined_data' / 'Energy_Intensity' / 'Energy_intensity_constants.xlsx',\n",
    "    index_col=[0,1,2])\n",
    "\n",
    "TS_cj = pd.read_excel(\n",
    "    directory_path / 'data' / 'cleaned_and_combined_data' / 'Type_Split' / 'Type_Split_ratios.xlsx',\n",
    "    index_col=0)\n",
    "\n",
    "lifetime = pd.read_excel(\n",
    "    directory_path / 'data' / 'regression_data' / 'Dwelling_Lifetime' / 'lifetime_regression.xlsx',\n",
    "    index_col=0)\n",
    "\n",
    "lifetime_standard_deviation = pd.read_excel(\n",
    "    directory_path / 'data' / 'regression_data' / 'Dwelling_Lifetime' / 'lifetime_regression.xlsx',\n",
    "    index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate out the lifetime and standard deviation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lifetime = lifetime.drop('std_dev', axis=1)\n",
    "lifetime_standard_deviation = lifetime_standard_deviation.drop('Avg_lifetime', axis=1)\n",
    "\n",
    "lifetime = lifetime.loc[:, 'Avg_lifetime'].to_numpy()\n",
    "lifetime\n",
    "\n",
    "lifetime_standard_deviation = lifetime_standard_deviation.loc[:, 'std_dev'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import DSM module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the name of the directory where the this file is present.\n",
    "current = os.path.dirname(os.path.realpath('this'))\n",
    " \n",
    "# Getting the parent directory name where the current directory is present.\n",
    "parent = os.path.dirname(current)\n",
    "#make the UA path\n",
    "module_path = parent + '/modules'\n",
    "#append path to options to import from\n",
    "sys.path.append(module_path)\n",
    "\n",
    "from dynamic_stock_model import DynamicStockModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate stock from pop/PpD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grace\\AppData\\Local\\Temp\\ipykernel_18972\\4106792660.py:1: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  stock_t = np.divide(pop.drop_duplicates(),PpD)\n"
     ]
    }
   ],
   "source": [
    "stock_t = np.divide(pop.drop_duplicates(),PpD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that does the stock driven modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_inflow_by_type(inflow_t):\n",
    "    SFH_inflow = pd.DataFrame()\n",
    "    TH_inflow = pd.DataFrame()\n",
    "    AB_inflow = pd.DataFrame()\n",
    "    for year in inflow_t.columns:\n",
    "        if int(year) <= 1955:\n",
    "            iteration_SFH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1955 and before','% SFH']\n",
    "                    )\n",
    "                )\n",
    "            SFH_inflow = pd.concat([SFH_inflow, iteration_SFH], axis=1)\n",
    "            iteration_TH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1955 and before','% TH']\n",
    "                    )\n",
    "                )\n",
    "            TH_inflow = pd.concat([TH_inflow, iteration_TH], axis=1)\n",
    "            iteration_AB = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1955 and before','% AB']\n",
    "                    )\n",
    "                )\n",
    "            AB_inflow = pd.concat([AB_inflow, iteration_AB], axis=1)\n",
    "        elif int(year) >= 1956 and int(year) <= 1970:\n",
    "            iteration_SFH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1956 - 1970','% SFH']\n",
    "                    )\n",
    "                )\n",
    "            SFH_inflow = pd.concat([SFH_inflow, iteration_SFH], axis=1)\n",
    "            iteration_TH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1956 - 1970','% TH']\n",
    "                    )\n",
    "                )\n",
    "            TH_inflow = pd.concat([TH_inflow, iteration_TH], axis=1)\n",
    "            iteration_AB = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1956 - 1970','% AB']\n",
    "                    )\n",
    "                )\n",
    "            AB_inflow = pd.concat([AB_inflow, iteration_AB], axis=1)\n",
    "        elif int(year) >= 1971 and int(year) <= 1980:\n",
    "            iteration_SFH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1971 - 1980','% SFH']\n",
    "                    )\n",
    "                )\n",
    "            SFH_inflow = pd.concat([SFH_inflow, iteration_SFH], axis=1)\n",
    "            iteration_TH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1971 - 1980','% TH']\n",
    "                    )\n",
    "                )\n",
    "            TH_inflow = pd.concat([TH_inflow, iteration_TH], axis=1)\n",
    "            iteration_AB = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1971 - 1980','% AB']\n",
    "                    )\n",
    "                )\n",
    "            AB_inflow = pd.concat([AB_inflow, iteration_AB], axis=1)\n",
    "        elif int(year) >= 1981 and int(year) <= 1990:\n",
    "            iteration_SFH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1981 - 1990','% SFH']\n",
    "                    )\n",
    "                )\n",
    "            SFH_inflow = pd.concat([SFH_inflow, iteration_SFH], axis=1)\n",
    "            iteration_TH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1981 - 1990','% TH']\n",
    "                    )\n",
    "                )\n",
    "            TH_inflow = pd.concat([TH_inflow, iteration_TH], axis=1)\n",
    "            iteration_AB = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1981 - 1990','% AB']\n",
    "                    )\n",
    "                )\n",
    "            AB_inflow = pd.concat([AB_inflow, iteration_AB], axis=1)\n",
    "        elif int(year) >= 1991 and int(year) <= 2000:\n",
    "            iteration_SFH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1991 - 2000','% SFH']\n",
    "                    )\n",
    "                )\n",
    "            SFH_inflow = pd.concat([SFH_inflow, iteration_SFH], axis=1)\n",
    "            iteration_TH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1991 - 2000','% TH']\n",
    "                    )\n",
    "                )\n",
    "            TH_inflow = pd.concat([TH_inflow, iteration_TH], axis=1)\n",
    "            iteration_AB = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1991 - 2000','% AB']\n",
    "                    )\n",
    "                )\n",
    "            AB_inflow = pd.concat([AB_inflow, iteration_AB], axis=1)\n",
    "        elif int(year) >= 2001 and int(year) <= 2010:\n",
    "            iteration_SFH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['2001 - 2010','% SFH']\n",
    "                    )\n",
    "                )\n",
    "            SFH_inflow = pd.concat([SFH_inflow, iteration_SFH], axis=1)\n",
    "            iteration_TH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['2001 - 2010','% TH']\n",
    "                    )\n",
    "                )\n",
    "            TH_inflow = pd.concat([TH_inflow, iteration_TH], axis=1)\n",
    "            iteration_AB = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['2001 - 2010','% AB']\n",
    "                    )\n",
    "                )\n",
    "            AB_inflow = pd.concat([AB_inflow, iteration_AB], axis=1)\n",
    "        elif int(year) >= 2011:\n",
    "            iteration_SFH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['2011 and after','% SFH']\n",
    "                    )\n",
    "                )\n",
    "            SFH_inflow = pd.concat([SFH_inflow, iteration_SFH], axis=1)\n",
    "            iteration_TH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['2011 and after','% TH']\n",
    "                    )\n",
    "                )\n",
    "            TH_inflow = pd.concat([TH_inflow, iteration_TH], axis=1)\n",
    "            iteration_AB = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['2011 and after','% AB']\n",
    "                    )\n",
    "                )\n",
    "            AB_inflow = pd.concat([AB_inflow, iteration_AB], axis=1)\n",
    "    return SFH_inflow, TH_inflow, AB_inflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_driven_model(stock):\n",
    "    dwellings_stock_driven = DynamicStockModel(t=np.arange(1600, 2051),\n",
    "                         s=stock['Pop'].to_numpy(),\n",
    "                         lt={'Type': 'Normal', \n",
    "                             'Mean': lifetime,\n",
    "                             'StdDev': lifetime_standard_deviation \n",
    "                             }\n",
    "                        )\n",
    "    \n",
    "    dwellings_stock_driven.compute_stock_driven_model(\n",
    "        NegativeInflowCorrect = True)\n",
    "    \n",
    "    inflow_t = pd.DataFrame(dwellings_stock_driven.i, index=np.arange(1600,2051))\n",
    "    \n",
    "    inflow_t_SFH, inflow_t_TH, inflow_t_AB = calculate_inflow_by_type(inflow_t.T)\n",
    "    inflow_t_SFH = inflow_t_SFH.T\n",
    "    inflow_t_TH = inflow_t_TH.T\n",
    "    inflow_t_AB = inflow_t_AB.T\n",
    "    \n",
    "    return inflow_t_SFH, inflow_t_TH, inflow_t_AB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the stock driven model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_SFH, i_TH, i_AB = stock_driven_model(stock_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that does the inflow driven modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inflow_driven_model(inflow):\n",
    "    dwellings_inflow_driven = DynamicStockModel(t=np.arange(1600, 2051),\n",
    "                    i=inflow[0],\n",
    "                    lt={'Type': 'Normal', \n",
    "                        'Mean': lifetime,\n",
    "                        'StdDev': lifetime_standard_deviation \n",
    "                        }\n",
    "                    )\n",
    "    dwellings_inflow_driven.compute_s_c_inflow_driven()\n",
    "\n",
    "    dwellings_inflow_driven.compute_stock_total()\n",
    "\n",
    "    dwellings_inflow_driven.compute_o_c_from_s_c()\n",
    "\n",
    "    return dwellings_inflow_driven.s_c, dwellings_inflow_driven.s, dwellings_inflow_driven.o_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the inflow driven model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_c_SFH, s_SFH, o_SFH = inflow_driven_model(i_SFH)\n",
    "s_c_TH, s_TH, o_TH = inflow_driven_model(i_TH)\n",
    "s_c_AB, s_AB, o_AB = inflow_driven_model(i_AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_SFH.rename(columns={0:'SFH'}, inplace=True)\n",
    "i_TH.rename(columns={0:'TH'}, inplace=True)\n",
    "i_AB.rename(columns={0:'AB'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make s_c arrays into dataframes for easier use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "UFApD.drop_duplicates(inplace=True)\n",
    "\n",
    "s_SFH_df = pd.DataFrame(s_SFH)\n",
    "s_SFH_df = s_SFH_df.set_index(UFApD.index)\n",
    "s_SFH_df.columns = ['SFH']\n",
    "\n",
    "s_TH_df = pd.DataFrame(s_TH)\n",
    "s_TH_df = s_TH_df.set_index(UFApD.index)\n",
    "s_TH_df.columns = ['TH']\n",
    "\n",
    "s_AB_df = pd.DataFrame(s_AB)\n",
    "s_AB_df = s_AB_df.set_index(UFApD.index)\n",
    "s_AB_df.columns = ['AB']\n",
    "\n",
    "s_c_SFH_df = pd.DataFrame(s_c_SFH)\n",
    "s_c_SFH_df = s_c_SFH_df.set_index(UFApD.index)\n",
    "s_c_SFH_df.columns = np.arange(1600, 2051)\n",
    "\n",
    "s_c_TH_df = pd.DataFrame(s_c_TH)\n",
    "s_c_TH_df = s_c_TH_df.set_index(UFApD.index)\n",
    "s_c_TH_df.columns = np.arange(1600, 2051)\n",
    "\n",
    "s_c_AB_df = pd.DataFrame(s_c_AB)\n",
    "s_c_AB_df = s_c_AB_df.set_index(UFApD.index)\n",
    "s_c_AB_df.columns = np.arange(1600, 2051)\n",
    "\n",
    "i_SFH_df = pd.DataFrame(i_SFH)\n",
    "i_SFH_df = i_SFH_df.set_index(UFApD.index)\n",
    "\n",
    "o_SFH_df = pd.DataFrame(o_SFH)\n",
    "o_SFH_df = o_SFH_df.set_index(UFApD.index)\n",
    "o_SFH_df.columns = np.arange(1600, 2051)\n",
    "\n",
    "i_TH_df = pd.DataFrame(i_TH)\n",
    "i_TH_df = i_TH_df.set_index(UFApD.index)\n",
    "\n",
    "o_TH_df = pd.DataFrame(o_TH)\n",
    "o_TH_df = o_TH_df.set_index(UFApD.index)\n",
    "o_TH_df.columns = np.arange(1600, 2051)\n",
    "\n",
    "i_AB_df = pd.DataFrame(i_AB)\n",
    "i_AB_df = i_AB_df.set_index(UFApD.index)\n",
    "\n",
    "o_AB_df = pd.DataFrame(o_AB)\n",
    "o_AB_df = o_AB_df.set_index(UFApD.index)\n",
    "o_AB_df.columns = np.arange(1600, 2051)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate s_c dataframes into the cohorts from tabula for each type for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "SFH_stock_by_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(s_c_SFH_df).loc[:,'1600':'1955'].sum(axis=1), \n",
    "          '1956-1970': pd.DataFrame(s_c_SFH_df).loc[:,'1956':'1970'].sum(axis=1), \n",
    "          '1971-1980': pd.DataFrame(s_c_SFH_df).loc[:,'1971':'1980'].sum(axis=1), \n",
    "          '1981-1990': pd.DataFrame(s_c_SFH_df).loc[:,'1981':'1990'].sum(axis=1), \n",
    "          '1991-2000': pd.DataFrame(s_c_SFH_df).loc[:,'1991':'2000'].sum(axis=1), \n",
    "          '2001-2010': pd.DataFrame(s_c_SFH_df).loc[:,'2001':'2010'].sum(axis=1), \n",
    "          'post-2010': pd.DataFrame(s_c_SFH_df).loc[:,'2011':'2050'].sum(axis=1)}\n",
    "          )\n",
    "\n",
    "TH_stock_by_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(s_c_TH_df).loc[:,'1600':'1955'].sum(axis=1), \n",
    "          '1956-1970': pd.DataFrame(s_c_TH_df).loc[:,'1956':'1970'].sum(axis=1), \n",
    "          '1971-1980': pd.DataFrame(s_c_TH_df).loc[:,'1971':'1980'].sum(axis=1), \n",
    "          '1981-1990': pd.DataFrame(s_c_TH_df).loc[:,'1981':'1990'].sum(axis=1), \n",
    "          '1991-2000': pd.DataFrame(s_c_TH_df).loc[:,'1991':'2000'].sum(axis=1), \n",
    "          '2001-2010': pd.DataFrame(s_c_TH_df).loc[:,'2001':'2010'].sum(axis=1), \n",
    "          'post-2010': pd.DataFrame(s_c_TH_df).loc[:,'2011':'2050'].sum(axis=1)}\n",
    "          )\n",
    "\n",
    "AB_stock_by_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(s_c_AB_df).loc[:,'1600':'1955'].sum(axis=1), \n",
    "          '1956-1970': pd.DataFrame(s_c_AB_df).loc[:,'1956':'1970'].sum(axis=1), \n",
    "          '1971-1980': pd.DataFrame(s_c_AB_df).loc[:,'1971':'1980'].sum(axis=1), \n",
    "          '1981-1990': pd.DataFrame(s_c_AB_df).loc[:,'1981':'1990'].sum(axis=1), \n",
    "          '1991-2000': pd.DataFrame(s_c_AB_df).loc[:,'1991':'2000'].sum(axis=1), \n",
    "          '2001-2010': pd.DataFrame(s_c_AB_df).loc[:,'2001':'2010'].sum(axis=1), \n",
    "          'post-2010': pd.DataFrame(s_c_AB_df).loc[:,'2011':'2050'].sum(axis=1)}\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total stock (s_total), total stock by cohort (s_c_total)\n",
    "\n",
    "Calculate stock_changes by inflow - outflow for each type and aggregated\n",
    "\n",
    "Calculate total inflows and outflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_total = s_SFH_df + s_TH_df + s_AB_df\n",
    "\n",
    "total_stock_by_tabula_cohort = SFH_stock_by_tabula_cohort + TH_stock_by_tabula_cohort + AB_stock_by_tabula_cohort\n",
    "\n",
    "stock_change_SFH = i_SFH_df.values - pd.DataFrame(o_SFH_df.sum(axis=1))\n",
    "stock_change_SFH = pd.DataFrame(stock_change_SFH, index=np.arange(1600,2051))\n",
    "\n",
    "stock_change_TH = i_TH_df.values - pd.DataFrame(o_TH_df.sum(axis=1))\n",
    "stock_change_TH = pd.DataFrame(stock_change_TH, index=np.arange(1600,2051))\n",
    "\n",
    "stock_change_AB = i_AB_df.values - pd.DataFrame(o_AB_df.sum(axis=1))\n",
    "stock_change_AB = pd.DataFrame(stock_change_AB, index=np.arange(1600,2051))\n",
    "\n",
    "stock_change_total = stock_change_SFH + stock_change_TH + stock_change_AB\n",
    "\n",
    "i_total = i_SFH_df.values + i_TH_df.values + i_AB_df.values\n",
    "i_total = pd.DataFrame(i_total, index=np.arange(1600,2051))\n",
    "\n",
    "o_total = o_SFH_df + o_TH_df + o_AB_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert number of dwellings into floor area by DSM cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_UFA_c_SFH = s_c_SFH_df @ np.diag(UFApD['UFApD SFH'])\n",
    "s_UFA_c_SFH = pd.DataFrame(s_UFA_c_SFH)\n",
    "s_UFA_c_SFH.columns = np.arange(1600, 2051)\n",
    "\n",
    "s_UFA_c_TH = s_c_TH_df @ np.diag(UFApD['UFApD TH'])\n",
    "s_UFA_c_TH = pd.DataFrame(s_UFA_c_TH)\n",
    "s_UFA_c_TH.columns = np.arange(1600, 2051)\n",
    "\n",
    "s_UFA_c_AB = s_c_AB_df @ np.diag(UFApD['UFApD AB'])\n",
    "s_UFA_c_AB = pd.DataFrame(s_UFA_c_AB)\n",
    "s_UFA_c_AB.columns = np.arange(1600, 2051)\n",
    "\n",
    "i_SFH_UFA = i_SFH_df.mul(UFApD['UFApD SFH'].values, axis=0)\n",
    "i_SFH_UFA = pd.DataFrame(i_SFH_UFA)\n",
    "\n",
    "\n",
    "o_SFH_UFA = o_SFH_df @ np.diag(UFApD['UFApD SFH'])\n",
    "o_SFH_UFA = pd.DataFrame(o_SFH_UFA)\n",
    "o_SFH_UFA.columns = np.arange(1600, 2051)\n",
    "\n",
    "i_TH_UFA = i_TH_df.mul(UFApD['UFApD TH'].values, axis=0)\n",
    "i_TH_UFA = pd.DataFrame(i_TH_UFA)\n",
    "\n",
    "\n",
    "o_TH_UFA = o_TH_df @ np.diag(UFApD['UFApD TH'])\n",
    "o_TH_UFA = pd.DataFrame(o_TH_UFA)\n",
    "o_TH_UFA.columns = np.arange(1600, 2051)\n",
    "\n",
    "i_AB_UFA = i_AB_df.mul(UFApD['UFApD AB'].values, axis=0)\n",
    "i_AB_UFA = pd.DataFrame(i_AB_UFA)\n",
    "\n",
    "o_AB_UFA = o_AB_df @ np.diag(UFApD['UFApD AB'])\n",
    "o_AB_UFA = pd.DataFrame(o_AB_UFA)\n",
    "o_AB_UFA.columns = np.arange(1600, 2051)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make s_c_UFA arrays into dataframes for easier use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1600</th>\n",
       "      <th>1601</th>\n",
       "      <th>1602</th>\n",
       "      <th>1603</th>\n",
       "      <th>1604</th>\n",
       "      <th>1605</th>\n",
       "      <th>1606</th>\n",
       "      <th>1607</th>\n",
       "      <th>1608</th>\n",
       "      <th>1609</th>\n",
       "      <th>...</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>2048</th>\n",
       "      <th>2049</th>\n",
       "      <th>2050</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>1.523141e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>1.523086e+06</td>\n",
       "      <td>1.834471e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>1.523027e+06</td>\n",
       "      <td>1.834405e+03</td>\n",
       "      <td>1.863730e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>1.522964e+06</td>\n",
       "      <td>1.834334e+03</td>\n",
       "      <td>1.863663e+03</td>\n",
       "      <td>1.893628e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>1.522896e+06</td>\n",
       "      <td>1.834258e+03</td>\n",
       "      <td>1.863591e+03</td>\n",
       "      <td>1.893560e+03</td>\n",
       "      <td>1.924186e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>4.272805e-05</td>\n",
       "      <td>5.968454e-08</td>\n",
       "      <td>7.029155e-08</td>\n",
       "      <td>8.275131e-08</td>\n",
       "      <td>9.738198e-08</td>\n",
       "      <td>1.145555e-07</td>\n",
       "      <td>1.347063e-07</td>\n",
       "      <td>1.583421e-07</td>\n",
       "      <td>1.860556e-07</td>\n",
       "      <td>2.185388e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004402e+06</td>\n",
       "      <td>1.009507e+06</td>\n",
       "      <td>1.014769e+06</td>\n",
       "      <td>1.020193e+06</td>\n",
       "      <td>1.025783e+06</td>\n",
       "      <td>1.031541e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>3.682353e-05</td>\n",
       "      <td>5.146158e-08</td>\n",
       "      <td>6.063637e-08</td>\n",
       "      <td>7.141901e-08</td>\n",
       "      <td>8.408653e-08</td>\n",
       "      <td>9.896290e-08</td>\n",
       "      <td>1.164269e-07</td>\n",
       "      <td>1.369212e-07</td>\n",
       "      <td>1.609628e-07</td>\n",
       "      <td>1.891559e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004402e+06</td>\n",
       "      <td>1.009507e+06</td>\n",
       "      <td>1.014769e+06</td>\n",
       "      <td>1.020193e+06</td>\n",
       "      <td>1.025783e+06</td>\n",
       "      <td>1.031541e+06</td>\n",
       "      <td>1.037471e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>3.171969e-05</td>\n",
       "      <td>4.435019e-08</td>\n",
       "      <td>5.228228e-08</td>\n",
       "      <td>6.160897e-08</td>\n",
       "      <td>7.257138e-08</td>\n",
       "      <td>8.545160e-08</td>\n",
       "      <td>1.005796e-07</td>\n",
       "      <td>1.183412e-07</td>\n",
       "      <td>1.391873e-07</td>\n",
       "      <td>1.636450e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004401e+06</td>\n",
       "      <td>1.009506e+06</td>\n",
       "      <td>1.014769e+06</td>\n",
       "      <td>1.020193e+06</td>\n",
       "      <td>1.025782e+06</td>\n",
       "      <td>1.031541e+06</td>\n",
       "      <td>1.037471e+06</td>\n",
       "      <td>1.043574e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>2.731010e-05</td>\n",
       "      <td>3.820313e-08</td>\n",
       "      <td>4.505747e-08</td>\n",
       "      <td>5.312087e-08</td>\n",
       "      <td>6.260305e-08</td>\n",
       "      <td>7.374951e-08</td>\n",
       "      <td>8.684757e-08</td>\n",
       "      <td>1.022333e-07</td>\n",
       "      <td>1.202998e-07</td>\n",
       "      <td>1.415066e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004401e+06</td>\n",
       "      <td>1.009506e+06</td>\n",
       "      <td>1.014768e+06</td>\n",
       "      <td>1.020192e+06</td>\n",
       "      <td>1.025782e+06</td>\n",
       "      <td>1.031541e+06</td>\n",
       "      <td>1.037471e+06</td>\n",
       "      <td>1.043574e+06</td>\n",
       "      <td>1.049852e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>2.350222e-05</td>\n",
       "      <td>3.289224e-08</td>\n",
       "      <td>3.881238e-08</td>\n",
       "      <td>4.578019e-08</td>\n",
       "      <td>5.397800e-08</td>\n",
       "      <td>6.361936e-08</td>\n",
       "      <td>7.495431e-08</td>\n",
       "      <td>8.827551e-08</td>\n",
       "      <td>1.039254e-07</td>\n",
       "      <td>1.223044e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004400e+06</td>\n",
       "      <td>1.009505e+06</td>\n",
       "      <td>1.014768e+06</td>\n",
       "      <td>1.020192e+06</td>\n",
       "      <td>1.025782e+06</td>\n",
       "      <td>1.031541e+06</td>\n",
       "      <td>1.037471e+06</td>\n",
       "      <td>1.043574e+06</td>\n",
       "      <td>1.049852e+06</td>\n",
       "      <td>1.056305e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows × 451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1600          1601          1602          1603          1604  \\\n",
       "Year                                                                         \n",
       "1600  1.523141e+06  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1601  1.523086e+06  1.834471e+03  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1602  1.523027e+06  1.834405e+03  1.863730e+03  0.000000e+00  0.000000e+00   \n",
       "1603  1.522964e+06  1.834334e+03  1.863663e+03  1.893628e+03  0.000000e+00   \n",
       "1604  1.522896e+06  1.834258e+03  1.863591e+03  1.893560e+03  1.924186e+03   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2046  4.272805e-05  5.968454e-08  7.029155e-08  8.275131e-08  9.738198e-08   \n",
       "2047  3.682353e-05  5.146158e-08  6.063637e-08  7.141901e-08  8.408653e-08   \n",
       "2048  3.171969e-05  4.435019e-08  5.228228e-08  6.160897e-08  7.257138e-08   \n",
       "2049  2.731010e-05  3.820313e-08  4.505747e-08  5.312087e-08  6.260305e-08   \n",
       "2050  2.350222e-05  3.289224e-08  3.881238e-08  4.578019e-08  5.397800e-08   \n",
       "\n",
       "              1605          1606          1607          1608          1609  \\\n",
       "Year                                                                         \n",
       "1600  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1601  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1602  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1603  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1604  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2046  1.145555e-07  1.347063e-07  1.583421e-07  1.860556e-07  2.185388e-07   \n",
       "2047  9.896290e-08  1.164269e-07  1.369212e-07  1.609628e-07  1.891559e-07   \n",
       "2048  8.545160e-08  1.005796e-07  1.183412e-07  1.391873e-07  1.636450e-07   \n",
       "2049  7.374951e-08  8.684757e-08  1.022333e-07  1.202998e-07  1.415066e-07   \n",
       "2050  6.361936e-08  7.495431e-08  8.827551e-08  1.039254e-07  1.223044e-07   \n",
       "\n",
       "      ...          2041          2042          2043          2044  \\\n",
       "Year  ...                                                           \n",
       "1600  ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1601  ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1602  ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1603  ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1604  ...  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "...   ...           ...           ...           ...           ...   \n",
       "2046  ...  1.004402e+06  1.009507e+06  1.014769e+06  1.020193e+06   \n",
       "2047  ...  1.004402e+06  1.009507e+06  1.014769e+06  1.020193e+06   \n",
       "2048  ...  1.004401e+06  1.009506e+06  1.014769e+06  1.020193e+06   \n",
       "2049  ...  1.004401e+06  1.009506e+06  1.014768e+06  1.020192e+06   \n",
       "2050  ...  1.004400e+06  1.009505e+06  1.014768e+06  1.020192e+06   \n",
       "\n",
       "              2045          2046          2047          2048          2049  \\\n",
       "Year                                                                         \n",
       "1600  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1601  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1602  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1603  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1604  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2046  1.025783e+06  1.031541e+06  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "2047  1.025783e+06  1.031541e+06  1.037471e+06  0.000000e+00  0.000000e+00   \n",
       "2048  1.025782e+06  1.031541e+06  1.037471e+06  1.043574e+06  0.000000e+00   \n",
       "2049  1.025782e+06  1.031541e+06  1.037471e+06  1.043574e+06  1.049852e+06   \n",
       "2050  1.025782e+06  1.031541e+06  1.037471e+06  1.043574e+06  1.049852e+06   \n",
       "\n",
       "              2050  \n",
       "Year                \n",
       "1600  0.000000e+00  \n",
       "1601  0.000000e+00  \n",
       "1602  0.000000e+00  \n",
       "1603  0.000000e+00  \n",
       "1604  0.000000e+00  \n",
       "...            ...  \n",
       "2046  0.000000e+00  \n",
       "2047  0.000000e+00  \n",
       "2048  0.000000e+00  \n",
       "2049  0.000000e+00  \n",
       "2050  1.056305e+06  \n",
       "\n",
       "[451 rows x 451 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UFApD.drop_duplicates(inplace=True)\n",
    "\n",
    "s_UFA_c_SFH_df = pd.DataFrame(s_UFA_c_SFH)\n",
    "s_UFA_c_SFH_df = s_UFA_c_SFH_df.set_index(UFApD.index)\n",
    "s_UFA_c_SFH_df.columns = np.arange(1600, 2051)\n",
    "s_UFA_c_SFH_df\n",
    "\n",
    "s_UFA_c_TH_df = pd.DataFrame(s_UFA_c_TH)\n",
    "s_UFA_c_TH_df = s_UFA_c_TH_df.set_index(UFApD.index)\n",
    "s_UFA_c_TH_df.columns = np.arange(1600, 2051)\n",
    "s_UFA_c_TH_df\n",
    "\n",
    "s_UFA_c_AB_df = pd.DataFrame(s_UFA_c_AB)\n",
    "s_UFA_c_AB_df = s_UFA_c_AB_df.set_index(UFApD.index)\n",
    "s_UFA_c_AB_df.columns = np.arange(1600, 2051)\n",
    "s_UFA_c_AB_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate s_c dataframes into the cohorts from tabula for each type for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "SFH_UFA_stock_by_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'1600':'1955'].sum(axis=1), \n",
    "          '1956-1970': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'1956':'1970'].sum(axis=1), \n",
    "          '1971-1980': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'1971':'1980'].sum(axis=1), \n",
    "          '1981-1990': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'1981':'1990'].sum(axis=1), \n",
    "          '1991-2000': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'1991':'2000'].sum(axis=1), \n",
    "          '2001-2010': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'2001':'2010'].sum(axis=1), \n",
    "          'post-2010': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'2011':'2050'].sum(axis=1)}\n",
    "          )\n",
    "\n",
    "TH_UFA_stock_by_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(s_UFA_c_TH_df).loc[:,'1600':'1955'].sum(axis=1), \n",
    "          '1956-1970': pd.DataFrame(s_UFA_c_TH_df).loc[:,'1956':'1970'].sum(axis=1), \n",
    "          '1971-1980': pd.DataFrame(s_UFA_c_TH_df).loc[:,'1971':'1980'].sum(axis=1), \n",
    "          '1981-1990': pd.DataFrame(s_UFA_c_TH_df).loc[:,'1981':'1990'].sum(axis=1), \n",
    "          '1991-2000': pd.DataFrame(s_UFA_c_TH_df).loc[:,'1991':'2000'].sum(axis=1), \n",
    "          '2001-2010': pd.DataFrame(s_UFA_c_TH_df).loc[:,'2001':'2010'].sum(axis=1), \n",
    "          'post-2010': pd.DataFrame(s_UFA_c_TH_df).loc[:,'2011':'2050'].sum(axis=1)}\n",
    "          )\n",
    "\n",
    "AB_UFA_stock_by_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(s_UFA_c_AB_df).loc[:,'1600':'1955'].sum(axis=1), \n",
    "          '1956-1970': pd.DataFrame(s_UFA_c_AB_df).loc[:,'1956':'1970'].sum(axis=1), \n",
    "          '1971-1980': pd.DataFrame(s_UFA_c_AB_df).loc[:,'1971':'1980'].sum(axis=1), \n",
    "          '1981-1990': pd.DataFrame(s_UFA_c_AB_df).loc[:,'1981':'1990'].sum(axis=1), \n",
    "          '1991-2000': pd.DataFrame(s_UFA_c_AB_df).loc[:,'1991':'2000'].sum(axis=1), \n",
    "          '2001-2010': pd.DataFrame(s_UFA_c_AB_df).loc[:,'2001':'2010'].sum(axis=1), \n",
    "          'post-2010': pd.DataFrame(s_UFA_c_AB_df).loc[:,'2011':'2050'].sum(axis=1)}\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total stock (s_total), total stock by cohort (s_c_total)\n",
    "\n",
    "Calculate stock_changes by inflow - outflow for each type and aggregated\n",
    "\n",
    "Calculate total inflows and outflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_UFA_total = s_UFA_c_SFH.sum(axis=1) + s_UFA_c_TH.sum(axis=1) + s_UFA_c_AB.sum(axis=1)\n",
    "\n",
    "total_stock_UFA_by_tabula_cohort = SFH_UFA_stock_by_tabula_cohort + TH_UFA_stock_by_tabula_cohort + AB_UFA_stock_by_tabula_cohort\n",
    "\n",
    "stock_change_SFH_UFA = i_SFH_UFA.values - pd.DataFrame(o_SFH_UFA.sum(axis=1))\n",
    "stock_change_SFH_UFA = pd.DataFrame(stock_change_SFH_UFA, index=np.arange(1600,2051))\n",
    "\n",
    "stock_change_TH_UFA = i_TH_UFA.values - pd.DataFrame(o_TH_UFA.sum(axis=1))\n",
    "stock_change_TH_UFA = pd.DataFrame(stock_change_TH_UFA, index=np.arange(1600,2051))\n",
    "\n",
    "stock_change_AB_UFA = i_AB_UFA.values - pd.DataFrame(o_AB_UFA.sum(axis=1))\n",
    "stock_change_AB_UFA = pd.DataFrame(stock_change_AB_UFA, index=np.arange(1600,2051))\n",
    "\n",
    "stock_change_total_UFA = stock_change_SFH_UFA + stock_change_TH_UFA + stock_change_AB_UFA\n",
    "\n",
    "i_total_UFA = i_SFH_UFA.values + i_TH_UFA.values + i_AB_UFA.values\n",
    "i_total_UFA = pd.DataFrame(i_total_UFA, index=np.arange(1600,2051))\n",
    "\n",
    "o_total_UFA = o_SFH_UFA + o_TH_UFA + o_AB_UFA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that calculates energy use for SFH, original renovation level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_use_calculation_SFH(stock_c_UFA):\n",
    "    energy_use_matrix = pd.DataFrame()\n",
    "    for year in stock_c_UFA.columns:\n",
    "        if int(year) <= 1955:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('pre 1955' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1956 and int(year) <= 1970:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('1956-70' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1971 and int(year) <= 1980:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('1971-80' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1981 and int(year) <= 1990:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('1981-90' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1991 and int(year) <= 2000:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('1991-2000' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 2001 and int(year) <= 2010:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('2001-2010' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 2011:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('2011-' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "    return energy_use_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function that spits out energy use of SFH by DSM cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_matrix_SFH = energy_use_calculation_SFH(s_UFA_c_SFH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate vector of energy use for SFH (not by cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_vector_SFH = energy_use_matrix_SFH.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that calculates energy use for TH, original renovation level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_use_calculation_TH(stock_c_UFA):\n",
    "    energy_use_matrix = pd.DataFrame()\n",
    "    for year in stock_c_UFA.columns:\n",
    "        if int(year) <= 1955:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('pre 1955' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1956 and int(year) <= 1970:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('1956-70' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1971 and int(year) <= 1980:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('1971-80' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1981 and int(year) <= 1990:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('1981-90' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1991 and int(year) <= 2000:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('1991-2000' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 2001 and int(year) <= 2010:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('2001-2010' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 2011:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('2011-' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "    return energy_use_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function that spits out energy use of TH by DSM cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_matrix_TH = energy_use_calculation_TH(s_UFA_c_TH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate vector of energy use for TH (not by cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_vector_TH = energy_use_matrix_TH.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that calculates energy use for AB, original renovation level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_use_calculation_AB(stock_c_UFA):\n",
    "    energy_use_matrix = pd.DataFrame()\n",
    "    for year in stock_c_UFA.columns:\n",
    "        if int(year) <= 1955:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('pre 1955' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1956 and int(year) <= 1970:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('1956-70' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1971 and int(year) <= 1980:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('1971-80' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1981 and int(year) <= 1990:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('1981-90' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1991 and int(year) <= 2000:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('1991-2000' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 2001 and int(year) <= 2010:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('2001-2010' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 2011:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('2011-' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "    return energy_use_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function that spits out energy use of AB by DSM cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_matrix_AB = energy_use_calculation_AB(s_UFA_c_AB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate vector of energy use for AB (not by cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_vector_AB = energy_use_matrix_AB.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total energy use matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_matrix_total = energy_use_matrix_SFH + energy_use_matrix_TH + energy_use_matrix_AB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate energy use vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SFH</th>\n",
       "      <th>TH</th>\n",
       "      <th>AB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>3.074960e+09</td>\n",
       "      <td>5.485634e+08</td>\n",
       "      <td>2.985356e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>3.078550e+09</td>\n",
       "      <td>5.492044e+08</td>\n",
       "      <td>2.988844e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>3.082188e+09</td>\n",
       "      <td>5.498543e+08</td>\n",
       "      <td>2.992382e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>3.085875e+09</td>\n",
       "      <td>5.505133e+08</td>\n",
       "      <td>2.995969e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>3.089610e+09</td>\n",
       "      <td>5.511815e+08</td>\n",
       "      <td>2.999607e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>4.589249e+10</td>\n",
       "      <td>1.091141e+10</td>\n",
       "      <td>8.806871e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>4.567120e+10</td>\n",
       "      <td>1.090384e+10</td>\n",
       "      <td>8.846273e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>4.544196e+10</td>\n",
       "      <td>1.089512e+10</td>\n",
       "      <td>8.885045e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>4.520471e+10</td>\n",
       "      <td>1.088525e+10</td>\n",
       "      <td>8.923188e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>4.495937e+10</td>\n",
       "      <td>1.087423e+10</td>\n",
       "      <td>8.960703e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               SFH            TH            AB\n",
       "Year                                          \n",
       "1600  3.074960e+09  5.485634e+08  2.985356e+08\n",
       "1601  3.078550e+09  5.492044e+08  2.988844e+08\n",
       "1602  3.082188e+09  5.498543e+08  2.992382e+08\n",
       "1603  3.085875e+09  5.505133e+08  2.995969e+08\n",
       "1604  3.089610e+09  5.511815e+08  2.999607e+08\n",
       "...            ...           ...           ...\n",
       "2046  4.589249e+10  1.091141e+10  8.806871e+09\n",
       "2047  4.567120e+10  1.090384e+10  8.846273e+09\n",
       "2048  4.544196e+10  1.089512e+10  8.885045e+09\n",
       "2049  4.520471e+10  1.088525e+10  8.923188e+09\n",
       "2050  4.495937e+10  1.087423e+10  8.960703e+09\n",
       "\n",
       "[451 rows x 3 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_use_vectors_concatenated = pd.concat([energy_use_vector_SFH, energy_use_vector_TH, energy_use_vector_AB], axis=1)\n",
    "energy_use_vectors_concatenated = energy_use_vectors_concatenated.rename(columns={0: 'SFH', 1: 'TH', 2: 'AB'})\n",
    "\n",
    "#energy_use_vectors_concatenated = pd.concat([energy_use_vectors_concatenat1, energy_use_vector_AB], axis=1)\n",
    "\n",
    "energy_use_vectors_concatenated "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put energy use matrix into tabula cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_matrix_total_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(energy_use_matrix_total).loc[:,'1600':'1955'].sum(axis=1)/1000000000, \n",
    "          '1956-1970': pd.DataFrame(energy_use_matrix_total).loc[:,'1956':'1970'].sum(axis=1)/1000000000, \n",
    "          '1971-1980': pd.DataFrame(energy_use_matrix_total).loc[:,'1971':'1980'].sum(axis=1)/1000000000, \n",
    "          '1981-1990': pd.DataFrame(energy_use_matrix_total).loc[:,'1981':'1990'].sum(axis=1)/1000000000, \n",
    "          '1991-2000': pd.DataFrame(energy_use_matrix_total).loc[:,'1991':'2000'].sum(axis=1)/1000000000, \n",
    "          '2001-2010': pd.DataFrame(energy_use_matrix_total).loc[:,'2001':'2010'].sum(axis=1)/1000000000, \n",
    "          'post-2010': pd.DataFrame(energy_use_matrix_total).loc[:,'2011':'2050'].sum(axis=1)/1000000000}\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total energy use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_energy_use = energy_use_vector_SFH + energy_use_vector_TH + energy_use_vector_AB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_SFH_df.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/s_SFH.xlsx')\n",
    "\n",
    "s_TH_df.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/s_TH.xlsx')\n",
    "\n",
    "s_AB_df.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/s_AB.xlsx')\n",
    "\n",
    "SFH_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/s_c_SFH.xlsx')\n",
    "\n",
    "TH_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/s_c_TH.xlsx')\n",
    "\n",
    "AB_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/s_c_AB.xlsx')\n",
    "\n",
    "stock_change_total.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/s_delta_total.xlsx')\n",
    "\n",
    "total_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/s_c_total.xlsx')\n",
    "\n",
    "pd.DataFrame(i_SFH).to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/i_SFH.xlsx')\n",
    "\n",
    "pd.DataFrame(i_TH).to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/i_TH.xlsx')\n",
    "\n",
    "pd.DataFrame(i_AB).to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/i_AB.xlsx')\n",
    "\n",
    "o_total.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/o_total.xlsx')\n",
    "\n",
    "i_total.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/i_total.xlsx')\n",
    "\n",
    "s_UFA_c_SFH_df.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/s_UFA_c_SFH.xlsx')\n",
    "\n",
    "s_UFA_c_TH_df.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/s_UFA_c_TH.xlsx')\n",
    "\n",
    "s_UFA_c_AB_df.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/s_UFA_c_AB.xlsx')\n",
    "\n",
    "SFH_UFA_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/s_UFA_tabula_SFH.xlsx')\n",
    "\n",
    "TH_UFA_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/s_UFA_tabula_TH.xlsx')\n",
    "\n",
    "AB_UFA_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/s_UFA_tabula_AB.xlsx')\n",
    "\n",
    "stock_change_total_UFA.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/s_delta_total_UFA.xlsx')\n",
    "\n",
    "total_stock_UFA_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/s_UFA_tabula_total.xlsx')\n",
    "\n",
    "i_SFH_UFA.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/i_SFH_UFA.xlsx')\n",
    "\n",
    "i_TH_UFA.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/i_TH_UFA.xlsx')\n",
    "\n",
    "i_AB_UFA.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/i_AB_UFA.xlsx')\n",
    "\n",
    "o_total_UFA.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/o_total_UFA.xlsx')\n",
    "\n",
    "i_total_UFA.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/i_total_UFA.xlsx')\n",
    "\n",
    "energy_use_vector_SFH.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/energy/energy_use_vector_SFH.xlsx')\n",
    "\n",
    "energy_use_vector_TH.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/energy/energy_use_vector_TH.xlsx')\n",
    "\n",
    "energy_use_vector_AB.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/energy/energy_use_vector_AB.xlsx')\n",
    "\n",
    "energy_use_matrix_total_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/energy/energy_use_matrix_total_tabula.xlsx')\n",
    "\n",
    "total_energy_use.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/energy/total_energy_use.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TEP4221",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
