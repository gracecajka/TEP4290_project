{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#* Import the code needed\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#* Define paths\n",
    "directory_path = Path('../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_excel(\n",
    "    directory_path / 'data' / 'regression_data' / 'Population' / 'regression_Population.xlsx',\n",
    "    index_col=0)\n",
    "\n",
    "PpD = pd.read_excel(\n",
    "    directory_path / 'data' / 'regression_data' / 'PpD' / 'regression_PpD.xlsx',\n",
    "    index_col=0)\n",
    "\n",
    "UFApD = pd.read_excel(\n",
    "    directory_path / 'data' / 'regression_data' / 'UFApD' / 'regression_UFApD.xlsx',\n",
    "    index_col=0)\n",
    "\n",
    "energy_intensity = pd.read_excel(\n",
    "    directory_path / 'data' / 'cleaned_and_combined_data' / 'Energy_Intensity' / 'Energy_intensity_constants.xlsx',\n",
    "    index_col=[0,1,2])\n",
    "\n",
    "TS_cj = pd.read_excel(\n",
    "    directory_path / 'data' / 'cleaned_and_combined_data' / 'Type_Split' / 'type_split_clean.xlsx',\n",
    "    index_col=0)\n",
    "\n",
    "lifetime = pd.read_excel(\n",
    "    directory_path / 'data' / 'regression_data' / 'Dwelling_Lifetime' / 'lifetime_regression.xlsx',\n",
    "    index_col=0)\n",
    "\n",
    "lifetime_standard_deviation = pd.read_excel(\n",
    "    directory_path / 'data' / 'regression_data' / 'Dwelling_Lifetime' / 'lifetime_regression.xlsx',\n",
    "    index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% SFH</th>\n",
       "      <th>% TH</th>\n",
       "      <th>% AB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age classes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>before 1900</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901-1955</th>\n",
       "      <td>0.554235</td>\n",
       "      <td>0.197740</td>\n",
       "      <td>0.248024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956 - 1970</th>\n",
       "      <td>0.529005</td>\n",
       "      <td>0.189334</td>\n",
       "      <td>0.281662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971 - 1980</th>\n",
       "      <td>0.572690</td>\n",
       "      <td>0.189063</td>\n",
       "      <td>0.238247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981 - 1990</th>\n",
       "      <td>0.612222</td>\n",
       "      <td>0.213791</td>\n",
       "      <td>0.173987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991 - 2000</th>\n",
       "      <td>0.476144</td>\n",
       "      <td>0.241475</td>\n",
       "      <td>0.282381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001 - 2010</th>\n",
       "      <td>0.336761</td>\n",
       "      <td>0.230478</td>\n",
       "      <td>0.432761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011 and after</th>\n",
       "      <td>0.340235</td>\n",
       "      <td>0.247552</td>\n",
       "      <td>0.412213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   % SFH      % TH      % AB\n",
       "Age classes                                 \n",
       "before 1900     0.980000  0.020000  0.000000\n",
       "1901-1955       0.554235  0.197740  0.248024\n",
       "1956 - 1970     0.529005  0.189334  0.281662\n",
       "1971 - 1980     0.572690  0.189063  0.238247\n",
       "1981 - 1990     0.612222  0.213791  0.173987\n",
       "1991 - 2000     0.476144  0.241475  0.282381\n",
       "2001 - 2010     0.336761  0.230478  0.432761\n",
       "2011 and after  0.340235  0.247552  0.412213"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_cj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_cj.loc['before 1900','% SFH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate out the lifetime and standard deviation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lifetime = lifetime.drop('std_dev', axis=1)\n",
    "lifetime_standard_deviation = lifetime_standard_deviation.drop('Avg_lifetime', axis=1)\n",
    "\n",
    "lifetime = lifetime.loc[:, 'Avg_lifetime'].to_numpy()\n",
    "lifetime\n",
    "\n",
    "lifetime_standard_deviation = lifetime_standard_deviation.loc[:, 'std_dev'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import DSM module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the name of the directory where the this file is present.\n",
    "current = os.path.dirname(os.path.realpath('this'))\n",
    " \n",
    "# Getting the parent directory name where the current directory is present.\n",
    "parent = os.path.dirname(current)\n",
    "#make the UA path\n",
    "module_path = parent + '/modules'\n",
    "#append path to options to import from\n",
    "sys.path.append(module_path)\n",
    "\n",
    "from dynamic_stock_model import DynamicStockModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate stock from pop/PpD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grace\\AppData\\Local\\Temp\\ipykernel_36408\\4106792660.py:1: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  stock_t = np.divide(pop.drop_duplicates(),PpD)\n"
     ]
    }
   ],
   "source": [
    "stock_t = np.divide(pop.drop_duplicates(),PpD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that does the stock driven modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_inflow_by_type(inflow_t):\n",
    "    SFH_inflow = pd.DataFrame()\n",
    "    TH_inflow = pd.DataFrame()\n",
    "    AB_inflow = pd.DataFrame()\n",
    "    for year in inflow_t.columns:\n",
    "        if int(year) <= 1900:\n",
    "            iteration_SFH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['before 1900','% SFH']\n",
    "                    )\n",
    "                )\n",
    "            SFH_inflow = pd.concat([SFH_inflow, iteration_SFH], axis=1)\n",
    "            iteration_TH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['before 1900','% TH']\n",
    "                    )\n",
    "                )\n",
    "            TH_inflow = pd.concat([TH_inflow, iteration_TH], axis=1)\n",
    "            iteration_AB = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['before 1900','% AB']\n",
    "                    )\n",
    "                )\n",
    "            AB_inflow = pd.concat([AB_inflow, iteration_AB], axis=1)\n",
    "        if int(year) >= 1901 and int(year) <= 1955:\n",
    "            iteration_SFH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1901-1955','% SFH']\n",
    "                    )\n",
    "                )\n",
    "            SFH_inflow = pd.concat([SFH_inflow, iteration_SFH], axis=1)\n",
    "            iteration_TH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1901-1955','% TH']\n",
    "                    )\n",
    "                )\n",
    "            TH_inflow = pd.concat([TH_inflow, iteration_TH], axis=1)\n",
    "            iteration_AB = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1901-1955','% AB']\n",
    "                    )\n",
    "                )\n",
    "            AB_inflow = pd.concat([AB_inflow, iteration_AB], axis=1)\n",
    "        elif int(year) >= 1956 and int(year) <= 1970:\n",
    "            iteration_SFH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1956 - 1970','% SFH']\n",
    "                    )\n",
    "                )\n",
    "            SFH_inflow = pd.concat([SFH_inflow, iteration_SFH], axis=1)\n",
    "            iteration_TH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1956 - 1970','% TH']\n",
    "                    )\n",
    "                )\n",
    "            TH_inflow = pd.concat([TH_inflow, iteration_TH], axis=1)\n",
    "            iteration_AB = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1956 - 1970','% AB']\n",
    "                    )\n",
    "                )\n",
    "            AB_inflow = pd.concat([AB_inflow, iteration_AB], axis=1)\n",
    "        elif int(year) >= 1971 and int(year) <= 1980:\n",
    "            iteration_SFH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1971 - 1980','% SFH']\n",
    "                    )\n",
    "                )\n",
    "            SFH_inflow = pd.concat([SFH_inflow, iteration_SFH], axis=1)\n",
    "            iteration_TH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1971 - 1980','% TH']\n",
    "                    )\n",
    "                )\n",
    "            TH_inflow = pd.concat([TH_inflow, iteration_TH], axis=1)\n",
    "            iteration_AB = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1971 - 1980','% AB']\n",
    "                    )\n",
    "                )\n",
    "            AB_inflow = pd.concat([AB_inflow, iteration_AB], axis=1)\n",
    "        elif int(year) >= 1981 and int(year) <= 1990:\n",
    "            iteration_SFH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1981 - 1990','% SFH']\n",
    "                    )\n",
    "                )\n",
    "            SFH_inflow = pd.concat([SFH_inflow, iteration_SFH], axis=1)\n",
    "            iteration_TH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1981 - 1990','% TH']\n",
    "                    )\n",
    "                )\n",
    "            TH_inflow = pd.concat([TH_inflow, iteration_TH], axis=1)\n",
    "            iteration_AB = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1981 - 1990','% AB']\n",
    "                    )\n",
    "                )\n",
    "            AB_inflow = pd.concat([AB_inflow, iteration_AB], axis=1)\n",
    "        elif int(year) >= 1991 and int(year) <= 2000:\n",
    "            iteration_SFH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1991 - 2000','% SFH']\n",
    "                    )\n",
    "                )\n",
    "            SFH_inflow = pd.concat([SFH_inflow, iteration_SFH], axis=1)\n",
    "            iteration_TH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1991 - 2000','% TH']\n",
    "                    )\n",
    "                )\n",
    "            TH_inflow = pd.concat([TH_inflow, iteration_TH], axis=1)\n",
    "            iteration_AB = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['1991 - 2000','% AB']\n",
    "                    )\n",
    "                )\n",
    "            AB_inflow = pd.concat([AB_inflow, iteration_AB], axis=1)\n",
    "        elif int(year) >= 2001 and int(year) <= 2010:\n",
    "            iteration_SFH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['2001 - 2010','% SFH']\n",
    "                    )\n",
    "                )\n",
    "            SFH_inflow = pd.concat([SFH_inflow, iteration_SFH], axis=1)\n",
    "            iteration_TH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['2001 - 2010','% TH']\n",
    "                    )\n",
    "                )\n",
    "            TH_inflow = pd.concat([TH_inflow, iteration_TH], axis=1)\n",
    "            iteration_AB = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['2001 - 2010','% AB']\n",
    "                    )\n",
    "                )\n",
    "            AB_inflow = pd.concat([AB_inflow, iteration_AB], axis=1)\n",
    "        elif int(year) >= 2011:\n",
    "            iteration_SFH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['2011 and after','% SFH']\n",
    "                    )\n",
    "                )\n",
    "            SFH_inflow = pd.concat([SFH_inflow, iteration_SFH], axis=1)\n",
    "            iteration_TH = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['2011 and after','% TH']\n",
    "                    )\n",
    "                )\n",
    "            TH_inflow = pd.concat([TH_inflow, iteration_TH], axis=1)\n",
    "            iteration_AB = pd.DataFrame(\n",
    "                np.multiply(\n",
    "                    inflow_t.loc[:,year],TS_cj.loc['2011 and after','% AB']\n",
    "                    )\n",
    "                )\n",
    "            AB_inflow = pd.concat([AB_inflow, iteration_AB], axis=1)\n",
    "    return SFH_inflow, TH_inflow, AB_inflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_driven_model(stock):\n",
    "    dwellings_stock_driven = DynamicStockModel(t=np.arange(1600, 2051),\n",
    "                         s=stock['Pop'].to_numpy(),\n",
    "                         lt={'Type': 'Normal', \n",
    "                             'Mean': lifetime,\n",
    "                             'StdDev': lifetime_standard_deviation \n",
    "                             }\n",
    "                        )\n",
    "    \n",
    "    dwellings_stock_driven.compute_stock_driven_model(\n",
    "        NegativeInflowCorrect = True)\n",
    "    \n",
    "    inflow_t = pd.DataFrame(dwellings_stock_driven.i, index=np.arange(1600,2051))\n",
    "    \n",
    "    inflow_t_SFH, inflow_t_TH, inflow_t_AB = calculate_inflow_by_type(inflow_t.T)\n",
    "    inflow_t_SFH = inflow_t_SFH.T\n",
    "    inflow_t_TH = inflow_t_TH.T\n",
    "    inflow_t_AB = inflow_t_AB.T\n",
    "    \n",
    "    return inflow_t_SFH, inflow_t_TH, inflow_t_AB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the stock driven model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_SFH, i_TH, i_AB = stock_driven_model(stock_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>72146.206526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>86.917974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>88.329757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>89.772627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>91.247654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>11708.234108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>11779.438077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>11852.658670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>11927.911469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>12005.203475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "1600  72146.206526\n",
       "1601     86.917974\n",
       "1602     88.329757\n",
       "1603     89.772627\n",
       "1604     91.247654\n",
       "...            ...\n",
       "2046  11708.234108\n",
       "2047  11779.438077\n",
       "2048  11852.658670\n",
       "2049  11927.911469\n",
       "2050  12005.203475\n",
       "\n",
       "[451 rows x 1 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_SFH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that does the inflow driven modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inflow_driven_model(inflow):\n",
    "    dwellings_inflow_driven = DynamicStockModel(t=np.arange(1600, 2051),\n",
    "                    i=inflow[0],\n",
    "                    lt={'Type': 'Normal', \n",
    "                        'Mean': lifetime,\n",
    "                        'StdDev': lifetime_standard_deviation \n",
    "                        }\n",
    "                    )\n",
    "    dwellings_inflow_driven.compute_s_c_inflow_driven()\n",
    "\n",
    "    dwellings_inflow_driven.compute_stock_total()\n",
    "\n",
    "    dwellings_inflow_driven.compute_o_c_from_s_c()\n",
    "\n",
    "    return dwellings_inflow_driven.s_c, dwellings_inflow_driven.s, dwellings_inflow_driven.o_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the inflow driven model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_c_SFH, s_SFH, o_SFH = inflow_driven_model(i_SFH)\n",
    "s_c_TH, s_TH, o_TH = inflow_driven_model(i_TH)\n",
    "s_c_AB, s_AB, o_AB = inflow_driven_model(i_AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.21148685e+04, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [7.21122802e+04, 8.68802196e+01, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [7.21094952e+04, 8.68771014e+01, 8.82913893e+01, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [1.50180529e-06, 2.10041699e-09, 2.47679356e-09, ...,\n",
       "        1.18526547e+04, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.29302854e-06, 1.80929321e-09, 2.13452952e-09, ...,\n",
       "        1.18526535e+04, 1.19279075e+04, 0.00000000e+00],\n",
       "       [1.11273977e-06, 1.55777033e-09, 1.83867762e-09, ...,\n",
       "        1.18526519e+04, 1.19279063e+04, 1.20051995e+04]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_c_SFH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_SFH.rename(columns={0:'SFH'}, inplace=True)\n",
    "i_TH.rename(columns={0:'TH'}, inplace=True)\n",
    "i_AB.rename(columns={0:'AB'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SFH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>72146.206526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>86.917974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>88.329757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>89.772627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>91.247654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>11708.234108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>11779.438077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>11852.658670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>11927.911469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>12005.203475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               SFH\n",
       "1600  72146.206526\n",
       "1601     86.917974\n",
       "1602     88.329757\n",
       "1603     89.772627\n",
       "1604     91.247654\n",
       "...            ...\n",
       "2046  11708.234108\n",
       "2047  11779.438077\n",
       "2048  11852.658670\n",
       "2049  11927.911469\n",
       "2050  12005.203475\n",
       "\n",
       "[451 rows x 1 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_SFH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make s_c arrays into dataframes for easier use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "UFApD.drop_duplicates(inplace=True)\n",
    "\n",
    "s_SFH_df = pd.DataFrame(s_SFH)\n",
    "s_SFH_df = s_SFH_df.set_index(UFApD.index)\n",
    "s_SFH_df.columns = ['SFH']\n",
    "\n",
    "s_TH_df = pd.DataFrame(s_TH)\n",
    "s_TH_df = s_TH_df.set_index(UFApD.index)\n",
    "s_TH_df.columns = ['TH']\n",
    "\n",
    "s_AB_df = pd.DataFrame(s_AB)\n",
    "s_AB_df = s_AB_df.set_index(UFApD.index)\n",
    "s_AB_df.columns = ['AB']\n",
    "\n",
    "s_c_SFH_df = pd.DataFrame(s_c_SFH)\n",
    "s_c_SFH_df = s_c_SFH_df.set_index(UFApD.index)\n",
    "s_c_SFH_df.columns = np.arange(1600, 2051)\n",
    "\n",
    "s_c_TH_df = pd.DataFrame(s_c_TH)\n",
    "s_c_TH_df = s_c_TH_df.set_index(UFApD.index)\n",
    "s_c_TH_df.columns = np.arange(1600, 2051)\n",
    "\n",
    "s_c_AB_df = pd.DataFrame(s_c_AB)\n",
    "s_c_AB_df = s_c_AB_df.set_index(UFApD.index)\n",
    "s_c_AB_df.columns = np.arange(1600, 2051)\n",
    "\n",
    "i_SFH_df = pd.DataFrame(i_SFH)\n",
    "i_SFH_df = i_SFH_df.set_index(UFApD.index)\n",
    "\n",
    "o_SFH_df = pd.DataFrame(o_SFH)\n",
    "o_SFH_df = o_SFH_df.set_index(UFApD.index)\n",
    "o_SFH_df.columns = np.arange(1600, 2051)\n",
    "\n",
    "i_TH_df = pd.DataFrame(i_TH)\n",
    "i_TH_df = i_TH_df.set_index(UFApD.index)\n",
    "\n",
    "o_TH_df = pd.DataFrame(o_TH)\n",
    "o_TH_df = o_TH_df.set_index(UFApD.index)\n",
    "o_TH_df.columns = np.arange(1600, 2051)\n",
    "\n",
    "i_AB_df = pd.DataFrame(i_AB)\n",
    "i_AB_df = i_AB_df.set_index(UFApD.index)\n",
    "\n",
    "o_AB_df = pd.DataFrame(o_AB)\n",
    "o_AB_df = o_AB_df.set_index(UFApD.index)\n",
    "o_AB_df.columns = np.arange(1600, 2051)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate s_c dataframes into the cohorts from tabula for each type for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "SFH_stock_by_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(s_c_SFH_df).loc[:,'1600':'1955'].sum(axis=1), \n",
    "          '1956-1970': pd.DataFrame(s_c_SFH_df).loc[:,'1956':'1970'].sum(axis=1), \n",
    "          '1971-1980': pd.DataFrame(s_c_SFH_df).loc[:,'1971':'1980'].sum(axis=1), \n",
    "          '1981-1990': pd.DataFrame(s_c_SFH_df).loc[:,'1981':'1990'].sum(axis=1), \n",
    "          '1991-2000': pd.DataFrame(s_c_SFH_df).loc[:,'1991':'2000'].sum(axis=1), \n",
    "          '2001-2010': pd.DataFrame(s_c_SFH_df).loc[:,'2001':'2010'].sum(axis=1), \n",
    "          'post-2010': pd.DataFrame(s_c_SFH_df).loc[:,'2011':'2050'].sum(axis=1)}\n",
    "          )\n",
    "\n",
    "TH_stock_by_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(s_c_TH_df).loc[:,'1600':'1955'].sum(axis=1), \n",
    "          '1956-1970': pd.DataFrame(s_c_TH_df).loc[:,'1956':'1970'].sum(axis=1), \n",
    "          '1971-1980': pd.DataFrame(s_c_TH_df).loc[:,'1971':'1980'].sum(axis=1), \n",
    "          '1981-1990': pd.DataFrame(s_c_TH_df).loc[:,'1981':'1990'].sum(axis=1), \n",
    "          '1991-2000': pd.DataFrame(s_c_TH_df).loc[:,'1991':'2000'].sum(axis=1), \n",
    "          '2001-2010': pd.DataFrame(s_c_TH_df).loc[:,'2001':'2010'].sum(axis=1), \n",
    "          'post-2010': pd.DataFrame(s_c_TH_df).loc[:,'2011':'2050'].sum(axis=1)}\n",
    "          )\n",
    "\n",
    "AB_stock_by_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(s_c_AB_df).loc[:,'1600':'1955'].sum(axis=1), \n",
    "          '1956-1970': pd.DataFrame(s_c_AB_df).loc[:,'1956':'1970'].sum(axis=1), \n",
    "          '1971-1980': pd.DataFrame(s_c_AB_df).loc[:,'1971':'1980'].sum(axis=1), \n",
    "          '1981-1990': pd.DataFrame(s_c_AB_df).loc[:,'1981':'1990'].sum(axis=1), \n",
    "          '1991-2000': pd.DataFrame(s_c_AB_df).loc[:,'1991':'2000'].sum(axis=1), \n",
    "          '2001-2010': pd.DataFrame(s_c_AB_df).loc[:,'2001':'2010'].sum(axis=1), \n",
    "          'post-2010': pd.DataFrame(s_c_AB_df).loc[:,'2011':'2050'].sum(axis=1)}\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total stock (s_total), total stock by cohort (s_c_total)\n",
    "\n",
    "Calculate stock_changes by inflow - outflow for each type and aggregated\n",
    "\n",
    "Calculate total inflows and outflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_total = s_SFH_df + s_TH_df + s_AB_df\n",
    "\n",
    "total_stock_by_tabula_cohort = SFH_stock_by_tabula_cohort + TH_stock_by_tabula_cohort + AB_stock_by_tabula_cohort\n",
    "\n",
    "stock_change_SFH = i_SFH_df.values - pd.DataFrame(o_SFH_df.sum(axis=1))\n",
    "stock_change_SFH = pd.DataFrame(stock_change_SFH, index=np.arange(1600,2051))\n",
    "\n",
    "stock_change_TH = i_TH_df.values - pd.DataFrame(o_TH_df.sum(axis=1))\n",
    "stock_change_TH = pd.DataFrame(stock_change_TH, index=np.arange(1600,2051))\n",
    "\n",
    "stock_change_AB = i_AB_df.values - pd.DataFrame(o_AB_df.sum(axis=1))\n",
    "stock_change_AB = pd.DataFrame(stock_change_AB, index=np.arange(1600,2051))\n",
    "\n",
    "stock_change_total = stock_change_SFH + stock_change_TH + stock_change_AB\n",
    "\n",
    "i_total = i_SFH_df.values + i_TH_df.values + i_AB_df.values\n",
    "i_total = pd.DataFrame(i_total, index=np.arange(1600,2051))\n",
    "\n",
    "o_total = o_SFH_df + o_TH_df + o_AB_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert number of dwellings into floor area by DSM cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_UFA_c_SFH = s_c_SFH_df @ np.diag(UFApD['UFApD SFH'])\n",
    "s_UFA_c_SFH = pd.DataFrame(s_UFA_c_SFH)\n",
    "s_UFA_c_SFH.columns = np.arange(1600, 2051)\n",
    "\n",
    "s_UFA_c_TH = s_c_TH_df @ np.diag(UFApD['UFApD TH'])\n",
    "s_UFA_c_TH = pd.DataFrame(s_UFA_c_TH)\n",
    "s_UFA_c_TH.columns = np.arange(1600, 2051)\n",
    "\n",
    "s_UFA_c_AB = s_c_AB_df @ np.diag(UFApD['UFApD AB'])\n",
    "s_UFA_c_AB = pd.DataFrame(s_UFA_c_AB)\n",
    "s_UFA_c_AB.columns = np.arange(1600, 2051)\n",
    "\n",
    "i_SFH_UFA = i_SFH_df.mul(UFApD['UFApD SFH'].values, axis=0)\n",
    "i_SFH_UFA = pd.DataFrame(i_SFH_UFA)\n",
    "\n",
    "o_SFH_UFA = o_SFH_df @ np.diag(UFApD['UFApD SFH'])\n",
    "o_SFH_UFA = pd.DataFrame(o_SFH_UFA)\n",
    "o_SFH_UFA.columns = np.arange(1600, 2051)\n",
    "\n",
    "i_TH_UFA = i_TH_df.mul(UFApD['UFApD TH'].values, axis=0)\n",
    "i_TH_UFA = pd.DataFrame(i_TH_UFA)\n",
    "\n",
    "o_TH_UFA = o_TH_df @ np.diag(UFApD['UFApD TH'])\n",
    "o_TH_UFA = pd.DataFrame(o_TH_UFA)\n",
    "o_TH_UFA.columns = np.arange(1600, 2051)\n",
    "\n",
    "i_AB_UFA = i_AB_df.mul(UFApD['UFApD AB'].values, axis=0)\n",
    "i_AB_UFA = pd.DataFrame(i_AB_UFA)\n",
    "\n",
    "o_AB_UFA = o_AB_df @ np.diag(UFApD['UFApD AB'])\n",
    "o_AB_UFA = pd.DataFrame(o_AB_UFA)\n",
    "o_AB_UFA.columns = np.arange(1600, 2051)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make s_c_UFA arrays into dataframes for easier use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1600</th>\n",
       "      <th>1601</th>\n",
       "      <th>1602</th>\n",
       "      <th>1603</th>\n",
       "      <th>1604</th>\n",
       "      <th>1605</th>\n",
       "      <th>1606</th>\n",
       "      <th>1607</th>\n",
       "      <th>1608</th>\n",
       "      <th>1609</th>\n",
       "      <th>...</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>2048</th>\n",
       "      <th>2049</th>\n",
       "      <th>2050</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004402e+06</td>\n",
       "      <td>1.009507e+06</td>\n",
       "      <td>1.014769e+06</td>\n",
       "      <td>1.020193e+06</td>\n",
       "      <td>1.025783e+06</td>\n",
       "      <td>1.031541e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004402e+06</td>\n",
       "      <td>1.009507e+06</td>\n",
       "      <td>1.014769e+06</td>\n",
       "      <td>1.020193e+06</td>\n",
       "      <td>1.025783e+06</td>\n",
       "      <td>1.031541e+06</td>\n",
       "      <td>1.037471e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004401e+06</td>\n",
       "      <td>1.009506e+06</td>\n",
       "      <td>1.014769e+06</td>\n",
       "      <td>1.020193e+06</td>\n",
       "      <td>1.025782e+06</td>\n",
       "      <td>1.031541e+06</td>\n",
       "      <td>1.037471e+06</td>\n",
       "      <td>1.043574e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004401e+06</td>\n",
       "      <td>1.009506e+06</td>\n",
       "      <td>1.014768e+06</td>\n",
       "      <td>1.020192e+06</td>\n",
       "      <td>1.025782e+06</td>\n",
       "      <td>1.031541e+06</td>\n",
       "      <td>1.037471e+06</td>\n",
       "      <td>1.043574e+06</td>\n",
       "      <td>1.049852e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004400e+06</td>\n",
       "      <td>1.009505e+06</td>\n",
       "      <td>1.014768e+06</td>\n",
       "      <td>1.020192e+06</td>\n",
       "      <td>1.025782e+06</td>\n",
       "      <td>1.031541e+06</td>\n",
       "      <td>1.037471e+06</td>\n",
       "      <td>1.043574e+06</td>\n",
       "      <td>1.049852e+06</td>\n",
       "      <td>1.056305e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows × 451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1600  1601  1602  1603  1604  1605  1606  1607  1608  1609  ...  \\\n",
       "Year                                                              ...   \n",
       "1600   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "1601   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "1602   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "1603   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "1604   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "2046   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2047   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2048   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2049   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2050   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "\n",
       "              2041          2042          2043          2044          2045  \\\n",
       "Year                                                                         \n",
       "1600  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1601  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1602  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1603  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1604  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2046  1.004402e+06  1.009507e+06  1.014769e+06  1.020193e+06  1.025783e+06   \n",
       "2047  1.004402e+06  1.009507e+06  1.014769e+06  1.020193e+06  1.025783e+06   \n",
       "2048  1.004401e+06  1.009506e+06  1.014769e+06  1.020193e+06  1.025782e+06   \n",
       "2049  1.004401e+06  1.009506e+06  1.014768e+06  1.020192e+06  1.025782e+06   \n",
       "2050  1.004400e+06  1.009505e+06  1.014768e+06  1.020192e+06  1.025782e+06   \n",
       "\n",
       "              2046          2047          2048          2049          2050  \n",
       "Year                                                                        \n",
       "1600  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "1601  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "1602  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "1603  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "1604  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "...            ...           ...           ...           ...           ...  \n",
       "2046  1.031541e+06  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "2047  1.031541e+06  1.037471e+06  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "2048  1.031541e+06  1.037471e+06  1.043574e+06  0.000000e+00  0.000000e+00  \n",
       "2049  1.031541e+06  1.037471e+06  1.043574e+06  1.049852e+06  0.000000e+00  \n",
       "2050  1.031541e+06  1.037471e+06  1.043574e+06  1.049852e+06  1.056305e+06  \n",
       "\n",
       "[451 rows x 451 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UFApD.drop_duplicates(inplace=True)\n",
    "\n",
    "s_UFA_c_SFH_df = pd.DataFrame(s_UFA_c_SFH)\n",
    "s_UFA_c_SFH_df = s_UFA_c_SFH_df.set_index(UFApD.index)\n",
    "s_UFA_c_SFH_df.columns = np.arange(1600, 2051)\n",
    "s_UFA_c_SFH_df\n",
    "\n",
    "s_UFA_c_TH_df = pd.DataFrame(s_UFA_c_TH)\n",
    "s_UFA_c_TH_df = s_UFA_c_TH_df.set_index(UFApD.index)\n",
    "s_UFA_c_TH_df.columns = np.arange(1600, 2051)\n",
    "s_UFA_c_TH_df\n",
    "\n",
    "s_UFA_c_AB_df = pd.DataFrame(s_UFA_c_AB)\n",
    "s_UFA_c_AB_df = s_UFA_c_AB_df.set_index(UFApD.index)\n",
    "s_UFA_c_AB_df.columns = np.arange(1600, 2051)\n",
    "s_UFA_c_AB_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate s_c dataframes into the cohorts from tabula for each type for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "SFH_UFA_stock_by_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'1600':'1955'].sum(axis=1), \n",
    "          '1956-1970': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'1956':'1970'].sum(axis=1), \n",
    "          '1971-1980': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'1971':'1980'].sum(axis=1), \n",
    "          '1981-1990': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'1981':'1990'].sum(axis=1), \n",
    "          '1991-2000': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'1991':'2000'].sum(axis=1), \n",
    "          '2001-2010': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'2001':'2010'].sum(axis=1), \n",
    "          'post-2010': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'2011':'2050'].sum(axis=1)}\n",
    "          )\n",
    "\n",
    "TH_UFA_stock_by_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(s_UFA_c_TH_df).loc[:,'1600':'1955'].sum(axis=1), \n",
    "          '1956-1970': pd.DataFrame(s_UFA_c_TH_df).loc[:,'1956':'1970'].sum(axis=1), \n",
    "          '1971-1980': pd.DataFrame(s_UFA_c_TH_df).loc[:,'1971':'1980'].sum(axis=1), \n",
    "          '1981-1990': pd.DataFrame(s_UFA_c_TH_df).loc[:,'1981':'1990'].sum(axis=1), \n",
    "          '1991-2000': pd.DataFrame(s_UFA_c_TH_df).loc[:,'1991':'2000'].sum(axis=1), \n",
    "          '2001-2010': pd.DataFrame(s_UFA_c_TH_df).loc[:,'2001':'2010'].sum(axis=1), \n",
    "          'post-2010': pd.DataFrame(s_UFA_c_TH_df).loc[:,'2011':'2050'].sum(axis=1)}\n",
    "          )\n",
    "\n",
    "AB_UFA_stock_by_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(s_UFA_c_AB_df).loc[:,'1600':'1955'].sum(axis=1), \n",
    "          '1956-1970': pd.DataFrame(s_UFA_c_AB_df).loc[:,'1956':'1970'].sum(axis=1), \n",
    "          '1971-1980': pd.DataFrame(s_UFA_c_AB_df).loc[:,'1971':'1980'].sum(axis=1), \n",
    "          '1981-1990': pd.DataFrame(s_UFA_c_AB_df).loc[:,'1981':'1990'].sum(axis=1), \n",
    "          '1991-2000': pd.DataFrame(s_UFA_c_AB_df).loc[:,'1991':'2000'].sum(axis=1), \n",
    "          '2001-2010': pd.DataFrame(s_UFA_c_AB_df).loc[:,'2001':'2010'].sum(axis=1), \n",
    "          'post-2010': pd.DataFrame(s_UFA_c_AB_df).loc[:,'2011':'2050'].sum(axis=1)}\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total stock (s_total), total stock by cohort (s_c_total)\n",
    "\n",
    "Calculate stock_changes by inflow - outflow for each type and aggregated\n",
    "\n",
    "Calculate total inflows and outflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_UFA_total = s_UFA_c_SFH.sum(axis=1) + s_UFA_c_TH.sum(axis=1) + s_UFA_c_AB.sum(axis=1)\n",
    "\n",
    "total_stock_UFA_by_tabula_cohort = SFH_UFA_stock_by_tabula_cohort + TH_UFA_stock_by_tabula_cohort + AB_UFA_stock_by_tabula_cohort\n",
    "\n",
    "stock_change_SFH_UFA = i_SFH_UFA.values - pd.DataFrame(o_SFH_UFA.sum(axis=1))\n",
    "stock_change_SFH_UFA = pd.DataFrame(stock_change_SFH_UFA, index=np.arange(1600,2051))\n",
    "\n",
    "stock_change_TH_UFA = i_TH_UFA.values - pd.DataFrame(o_TH_UFA.sum(axis=1))\n",
    "stock_change_TH_UFA = pd.DataFrame(stock_change_TH_UFA, index=np.arange(1600,2051))\n",
    "\n",
    "stock_change_AB_UFA = i_AB_UFA.values - pd.DataFrame(o_AB_UFA.sum(axis=1))\n",
    "stock_change_AB_UFA = pd.DataFrame(stock_change_AB_UFA, index=np.arange(1600,2051))\n",
    "\n",
    "stock_change_total_UFA = stock_change_SFH_UFA + stock_change_TH_UFA + stock_change_AB_UFA\n",
    "\n",
    "i_total_UFA = i_SFH_UFA.values + i_TH_UFA.values + i_AB_UFA.values\n",
    "i_total_UFA = pd.DataFrame(i_total_UFA, index=np.arange(1600,2051))\n",
    "\n",
    "o_total_UFA = o_SFH_UFA + o_TH_UFA + o_AB_UFA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that calculates energy use for SFH, original renovation level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_use_calculation_SFH(stock_c_UFA):\n",
    "    energy_use_matrix = pd.DataFrame()\n",
    "    for year in stock_c_UFA.columns:\n",
    "        if int(year) <= 1955:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('pre 1955' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1956 and int(year) <= 1970:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('1956-70' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1971 and int(year) <= 1980:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('1971-80' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1981 and int(year) <= 1990:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('1981-90' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1991 and int(year) <= 2000:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('1991-2000' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 2001 and int(year) <= 2010:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('2001-2010' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 2011:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('2011-' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "    return energy_use_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function that spits out energy use of SFH by DSM cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_matrix_SFH = energy_use_calculation_SFH(s_UFA_c_SFH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate vector of energy use for SFH (not by cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_vector_SFH = energy_use_matrix_SFH.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that calculates energy use for TH, original renovation level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_use_calculation_TH(stock_c_UFA):\n",
    "    energy_use_matrix = pd.DataFrame()\n",
    "    for year in stock_c_UFA.columns:\n",
    "        if int(year) <= 1955:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('pre 1955' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1956 and int(year) <= 1970:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('1956-70' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1971 and int(year) <= 1980:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('1971-80' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1981 and int(year) <= 1990:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('1981-90' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1991 and int(year) <= 2000:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('1991-2000' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 2001 and int(year) <= 2010:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('2001-2010' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 2011:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('2011-' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "    return energy_use_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function that spits out energy use of TH by DSM cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_matrix_TH = energy_use_calculation_TH(s_UFA_c_TH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate vector of energy use for TH (not by cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_vector_TH = energy_use_matrix_TH.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that calculates energy use for AB, original renovation level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_use_calculation_AB(stock_c_UFA):\n",
    "    energy_use_matrix = pd.DataFrame()\n",
    "    for year in stock_c_UFA.columns:\n",
    "        if int(year) <= 1955:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('pre 1955' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1956 and int(year) <= 1970:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('1956-70' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1971 and int(year) <= 1980:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('1971-80' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1981 and int(year) <= 1990:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('1981-90' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1991 and int(year) <= 2000:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('1991-2000' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 2001 and int(year) <= 2010:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('2001-2010' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 2011:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('2011-' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "    return energy_use_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function that spits out energy use of AB by DSM cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_matrix_AB = energy_use_calculation_AB(s_UFA_c_AB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate vector of energy use for AB (not by cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_vector_AB = energy_use_matrix_AB.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total energy use matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_matrix_total = energy_use_matrix_SFH + energy_use_matrix_TH + energy_use_matrix_AB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate energy use vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SFH</th>\n",
       "      <th>TH</th>\n",
       "      <th>AB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>5.437150e+09</td>\n",
       "      <td>5.548318e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>5.443498e+09</td>\n",
       "      <td>5.554801e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>5.449931e+09</td>\n",
       "      <td>5.561374e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>5.456449e+09</td>\n",
       "      <td>5.568039e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>5.463054e+09</td>\n",
       "      <td>5.574798e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>4.811045e+10</td>\n",
       "      <td>1.033055e+10</td>\n",
       "      <td>8.446063e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>4.782838e+10</td>\n",
       "      <td>1.033882e+10</td>\n",
       "      <td>8.495300e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>4.753928e+10</td>\n",
       "      <td>1.034571e+10</td>\n",
       "      <td>8.543762e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>4.724309e+10</td>\n",
       "      <td>1.035121e+10</td>\n",
       "      <td>8.591448e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>4.693974e+10</td>\n",
       "      <td>1.035532e+10</td>\n",
       "      <td>8.638358e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               SFH            TH            AB\n",
       "Year                                          \n",
       "1600  5.437150e+09  5.548318e+07  0.000000e+00\n",
       "1601  5.443498e+09  5.554801e+07  0.000000e+00\n",
       "1602  5.449931e+09  5.561374e+07  0.000000e+00\n",
       "1603  5.456449e+09  5.568039e+07  0.000000e+00\n",
       "1604  5.463054e+09  5.574798e+07  0.000000e+00\n",
       "...            ...           ...           ...\n",
       "2046  4.811045e+10  1.033055e+10  8.446063e+09\n",
       "2047  4.782838e+10  1.033882e+10  8.495300e+09\n",
       "2048  4.753928e+10  1.034571e+10  8.543762e+09\n",
       "2049  4.724309e+10  1.035121e+10  8.591448e+09\n",
       "2050  4.693974e+10  1.035532e+10  8.638358e+09\n",
       "\n",
       "[451 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_use_vectors_concatenated = pd.concat([energy_use_vector_SFH, energy_use_vector_TH, energy_use_vector_AB], axis=1)\n",
    "energy_use_vectors_concatenated = energy_use_vectors_concatenated.rename(columns={0: 'SFH', 1: 'TH', 2: 'AB'})\n",
    "\n",
    "#energy_use_vectors_concatenated = pd.concat([energy_use_vectors_concatenat1, energy_use_vector_AB], axis=1)\n",
    "\n",
    "energy_use_vectors_concatenated "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put energy use matrix into tabula cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_matrix_total_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(energy_use_matrix_total).loc[:,'1600':'1955'].sum(axis=1)/1000000000, \n",
    "          '1956-1970': pd.DataFrame(energy_use_matrix_total).loc[:,'1956':'1970'].sum(axis=1)/1000000000, \n",
    "          '1971-1980': pd.DataFrame(energy_use_matrix_total).loc[:,'1971':'1980'].sum(axis=1)/1000000000, \n",
    "          '1981-1990': pd.DataFrame(energy_use_matrix_total).loc[:,'1981':'1990'].sum(axis=1)/1000000000, \n",
    "          '1991-2000': pd.DataFrame(energy_use_matrix_total).loc[:,'1991':'2000'].sum(axis=1)/1000000000, \n",
    "          '2001-2010': pd.DataFrame(energy_use_matrix_total).loc[:,'2001':'2010'].sum(axis=1)/1000000000, \n",
    "          'post-2010': pd.DataFrame(energy_use_matrix_total).loc[:,'2011':'2050'].sum(axis=1)/1000000000}\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total energy use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_energy_use = energy_use_vector_SFH + energy_use_vector_TH + energy_use_vector_AB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_SFH_df.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/s_SFH.xlsx')\n",
    "\n",
    "s_TH_df.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/s_TH.xlsx')\n",
    "\n",
    "s_AB_df.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/s_AB.xlsx')\n",
    "\n",
    "SFH_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/s_c_SFH.xlsx')\n",
    "\n",
    "TH_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/s_c_TH.xlsx')\n",
    "\n",
    "AB_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/s_c_AB.xlsx')\n",
    "\n",
    "stock_change_total.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/s_delta_total.xlsx')\n",
    "\n",
    "total_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/s_c_total.xlsx')\n",
    "\n",
    "pd.DataFrame(i_SFH).to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/i_SFH.xlsx')\n",
    "\n",
    "pd.DataFrame(i_TH).to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/i_TH.xlsx')\n",
    "\n",
    "pd.DataFrame(i_AB).to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/i_AB.xlsx')\n",
    "\n",
    "o_total.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/o_total.xlsx')\n",
    "\n",
    "i_total.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/number_of_dwellings/i_total.xlsx')\n",
    "\n",
    "s_UFA_c_SFH_df.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/s_UFA_c_SFH.xlsx')\n",
    "\n",
    "s_UFA_c_TH_df.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/s_UFA_c_TH.xlsx')\n",
    "\n",
    "s_UFA_c_AB_df.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/s_UFA_c_AB.xlsx')\n",
    "\n",
    "SFH_UFA_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/s_UFA_tabula_SFH.xlsx')\n",
    "\n",
    "TH_UFA_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/s_UFA_tabula_TH.xlsx')\n",
    "\n",
    "AB_UFA_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/s_UFA_tabula_AB.xlsx')\n",
    "\n",
    "stock_change_total_UFA.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/s_delta_total_UFA.xlsx')\n",
    "\n",
    "total_stock_UFA_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/s_UFA_tabula_total.xlsx')\n",
    "\n",
    "i_SFH_UFA.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/i_SFH_UFA.xlsx')\n",
    "\n",
    "i_TH_UFA.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/i_TH_UFA.xlsx')\n",
    "\n",
    "i_AB_UFA.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/i_AB_UFA.xlsx')\n",
    "\n",
    "o_total_UFA.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/o_total_UFA.xlsx')\n",
    "\n",
    "i_total_UFA.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/UFA/i_total_UFA.xlsx')\n",
    "\n",
    "energy_use_vector_SFH.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/energy/energy_use_vector_SFH.xlsx')\n",
    "\n",
    "energy_use_vector_TH.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/energy/energy_use_vector_TH.xlsx')\n",
    "\n",
    "energy_use_vector_AB.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/energy/energy_use_vector_AB.xlsx')\n",
    "\n",
    "energy_use_matrix_total_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/energy/energy_use_matrix_total_tabula.xlsx')\n",
    "\n",
    "total_energy_use.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/energy/total_energy_use.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TEP4221",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
