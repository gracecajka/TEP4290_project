{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#* Import the code needed\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set directory path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#* Define paths\n",
    "directory_path = Path('../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.read_excel(\n",
    "    directory_path / 'data' / 'regression_data' / 'Population' / 'regression_Population.xlsx',\n",
    "    index_col=0)\n",
    "\n",
    "PpD = pd.read_excel(\n",
    "    directory_path / 'data' / 'regression_data' / 'PpD' / 'regression_PpD.xlsx',\n",
    "    index_col=0)\n",
    "\n",
    "UFApD = pd.read_excel(\n",
    "    directory_path / 'data' / 'regression_data' / 'UFApD' / 'regression_UFApD.xlsx',\n",
    "    index_col=0)\n",
    "\n",
    "energy_intensity = pd.read_excel(\n",
    "    directory_path / 'data' / 'cleaned_and_combined_data' / 'Energy_Intensity' / 'Energy_intensity_constants.xlsx',\n",
    "    index_col=[0,1,2])\n",
    "\n",
    "TS_cj = pd.read_excel(\n",
    "    directory_path / 'data' / 'cleaned_and_combined_data' / 'Type_Split' / 'Type_Split_ratios.xlsx',\n",
    "    index_col=0)\n",
    "\n",
    "lifetime = pd.read_excel(\n",
    "    directory_path / 'data' / 'regression_data' / 'Dwelling_Lifetime' / 'lifetime_regression.xlsx',\n",
    "    index_col=0)\n",
    "\n",
    "lifetime_standard_deviation = pd.read_excel(\n",
    "    directory_path / 'data' / 'regression_data' / 'Dwelling_Lifetime' / 'lifetime_regression.xlsx',\n",
    "    index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate out the lifetime and standard deviation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_lifetime</th>\n",
       "      <th>std_dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>150.260987</td>\n",
       "      <td>45.124627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>150.260984</td>\n",
       "      <td>45.124626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>150.260981</td>\n",
       "      <td>45.124624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>150.260978</td>\n",
       "      <td>45.124623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>150.260975</td>\n",
       "      <td>45.124621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>95.699156</td>\n",
       "      <td>19.265274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>95.664208</td>\n",
       "      <td>19.252439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>95.630580</td>\n",
       "      <td>19.240100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>95.598222</td>\n",
       "      <td>19.228236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>95.567090</td>\n",
       "      <td>19.216831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Avg_lifetime    std_dev\n",
       "1600    150.260987  45.124627\n",
       "1601    150.260984  45.124626\n",
       "1602    150.260981  45.124624\n",
       "1603    150.260978  45.124623\n",
       "1604    150.260975  45.124621\n",
       "...            ...        ...\n",
       "2046     95.699156  19.265274\n",
       "2047     95.664208  19.252439\n",
       "2048     95.630580  19.240100\n",
       "2049     95.598222  19.228236\n",
       "2050     95.567090  19.216831\n",
       "\n",
       "[451 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lifetime_standard_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lifetime = lifetime.drop('std_dev', axis=1)\n",
    "lifetime_standard_deviation = lifetime_standard_deviation.drop('Avg_lifetime', axis=1)\n",
    "\n",
    "lifetime = lifetime.loc[:, 'Avg_lifetime'].to_numpy()\n",
    "lifetime\n",
    "\n",
    "lifetime_standard_deviation = lifetime_standard_deviation.loc[:, 'std_dev'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import DSM module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the name of the directory where the this file is present.\n",
    "current = os.path.dirname(os.path.realpath('this'))\n",
    " \n",
    "# Getting the parent directory name where the current directory is present.\n",
    "parent = os.path.dirname(current)\n",
    "#make the UA path\n",
    "module_path = parent + '/modules'\n",
    "#append path to options to import from\n",
    "sys.path.append(module_path)\n",
    "\n",
    "from dynamic_stock_model import DynamicStockModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate stock from pop/PpD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grace\\AppData\\Local\\Temp\\ipykernel_42060\\4106792660.py:1: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  stock_t = np.divide(pop.drop_duplicates(),PpD)\n"
     ]
    }
   ],
   "source": [
    "stock_t = np.divide(pop.drop_duplicates(),PpD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that does the stock driven modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_driven_model(stock):\n",
    "    dwellings_stock_driven = DynamicStockModel(t=np.arange(1600, 2051),\n",
    "                         s=stock['Pop'].to_numpy(),\n",
    "                         lt={'Type': 'Normal', \n",
    "                             'Mean': lifetime,\n",
    "                             'StdDev': lifetime_standard_deviation \n",
    "                             }\n",
    "                        )\n",
    "    \n",
    "    dwellings_stock_driven.compute_stock_driven_model(\n",
    "        NegativeInflowCorrect = True)\n",
    "    \n",
    "    inflow_t = pd.DataFrame(dwellings_stock_driven.i)\n",
    "\n",
    "    inflow_t_SFH = np.multiply(inflow_t,TS_cj['SFH_ratio'])\n",
    "    inflow_t_TH = np.multiply(inflow_t,TS_cj['TH_ratio'])\n",
    "    inflow_t_AB = np.multiply(inflow_t,TS_cj['AB_ratio'])\n",
    "    \n",
    "    return inflow_t_SFH, inflow_t_TH, inflow_t_AB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the stock driven model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_SFH, i_TH, i_AB = stock_driven_model(stock_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that does the inflow driven modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inflow_driven_model(inflow):\n",
    "    dwellings_inflow_driven = DynamicStockModel(t=np.arange(1600, 2051),\n",
    "                    i=inflow[0],\n",
    "                    lt={'Type': 'Normal', \n",
    "                        'Mean': lifetime,\n",
    "                        'StdDev': lifetime_standard_deviation \n",
    "                        }\n",
    "                    )\n",
    "    dwellings_inflow_driven.compute_s_c_inflow_driven()\n",
    "\n",
    "    dwellings_inflow_driven.compute_stock_total()\n",
    "\n",
    "    dwellings_inflow_driven.compute_o_c_from_s_c()\n",
    "\n",
    "    return dwellings_inflow_driven.s_c, dwellings_inflow_driven.s, dwellings_inflow_driven.o_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the inflow driven model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_c_SFH, s_SFH, o_SFH = inflow_driven_model(i_SFH)\n",
    "s_c_TH, s_TH, o_TH = inflow_driven_model(i_TH)\n",
    "s_c_AB, s_AB, o_AB = inflow_driven_model(i_AB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make s_c arrays into dataframes for easier use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "UFApD.drop_duplicates(inplace=True)\n",
    "\n",
    "s_SFH_df = pd.DataFrame(s_SFH)\n",
    "s_SFH_df = s_SFH_df.set_index(UFApD.index)\n",
    "s_SFH_df.columns = ['SFH']\n",
    "\n",
    "s_TH_df = pd.DataFrame(s_TH)\n",
    "s_TH_df = s_TH_df.set_index(UFApD.index)\n",
    "s_TH_df.columns = ['TH']\n",
    "\n",
    "s_AB_df = pd.DataFrame(s_AB)\n",
    "s_AB_df = s_AB_df.set_index(UFApD.index)\n",
    "s_AB_df.columns = ['AB']\n",
    "\n",
    "s_c_SFH_df = pd.DataFrame(s_c_SFH)\n",
    "s_c_SFH_df = s_c_SFH_df.set_index(UFApD.index)\n",
    "s_c_SFH_df.columns = np.arange(1600, 2051)\n",
    "\n",
    "s_c_TH_df = pd.DataFrame(s_c_TH)\n",
    "s_c_TH_df = s_c_TH_df.set_index(UFApD.index)\n",
    "s_c_TH_df.columns = np.arange(1600, 2051)\n",
    "\n",
    "s_c_AB_df = pd.DataFrame(s_c_AB)\n",
    "s_c_AB_df = s_c_AB_df.set_index(UFApD.index)\n",
    "s_c_AB_df.columns = np.arange(1600, 2051)\n",
    "\n",
    "i_SFH_df = pd.DataFrame(i_SFH)\n",
    "i_SFH_df = i_SFH_df.set_index(UFApD.index)\n",
    "\n",
    "o_SFH_df = pd.DataFrame(o_SFH)\n",
    "o_SFH_df = o_SFH_df.set_index(UFApD.index)\n",
    "o_SFH_df.columns = np.arange(1600, 2051)\n",
    "\n",
    "i_TH_df = pd.DataFrame(i_TH)\n",
    "i_TH_df = i_TH_df.set_index(UFApD.index)\n",
    "\n",
    "o_TH_df = pd.DataFrame(o_TH)\n",
    "o_TH_df = o_TH_df.set_index(UFApD.index)\n",
    "o_TH_df.columns = np.arange(1600, 2051)\n",
    "\n",
    "i_AB_df = pd.DataFrame(i_AB)\n",
    "i_AB_df = i_AB_df.set_index(UFApD.index)\n",
    "\n",
    "o_AB_df = pd.DataFrame(o_AB)\n",
    "o_AB_df = o_AB_df.set_index(UFApD.index)\n",
    "o_AB_df.columns = np.arange(1600, 2051)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate s_c dataframes into the cohorts from tabula for each type for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "SFH_stock_by_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(s_c_SFH_df).loc[:,'1600':'1955'].sum(axis=1), \n",
    "          '1956-1970': pd.DataFrame(s_c_SFH_df).loc[:,'1956':'1970'].sum(axis=1), \n",
    "          '1971-1980': pd.DataFrame(s_c_SFH_df).loc[:,'1971':'1980'].sum(axis=1), \n",
    "          '1981-1990': pd.DataFrame(s_c_SFH_df).loc[:,'1981':'1990'].sum(axis=1), \n",
    "          '1991-2000': pd.DataFrame(s_c_SFH_df).loc[:,'1991':'2000'].sum(axis=1), \n",
    "          '2001-2010': pd.DataFrame(s_c_SFH_df).loc[:,'2001':'2010'].sum(axis=1), \n",
    "          'post-2010': pd.DataFrame(s_c_SFH_df).loc[:,'2011':'2050'].sum(axis=1)}\n",
    "          )\n",
    "\n",
    "TH_stock_by_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(s_c_TH_df).loc[:,'1600':'1955'].sum(axis=1), \n",
    "          '1956-1970': pd.DataFrame(s_c_TH_df).loc[:,'1956':'1970'].sum(axis=1), \n",
    "          '1971-1980': pd.DataFrame(s_c_TH_df).loc[:,'1971':'1980'].sum(axis=1), \n",
    "          '1981-1990': pd.DataFrame(s_c_TH_df).loc[:,'1981':'1990'].sum(axis=1), \n",
    "          '1991-2000': pd.DataFrame(s_c_TH_df).loc[:,'1991':'2000'].sum(axis=1), \n",
    "          '2001-2010': pd.DataFrame(s_c_TH_df).loc[:,'2001':'2010'].sum(axis=1), \n",
    "          'post-2010': pd.DataFrame(s_c_TH_df).loc[:,'2011':'2050'].sum(axis=1)}\n",
    "          )\n",
    "\n",
    "AB_stock_by_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(s_c_AB_df).loc[:,'1600':'1955'].sum(axis=1), \n",
    "          '1956-1970': pd.DataFrame(s_c_AB_df).loc[:,'1956':'1970'].sum(axis=1), \n",
    "          '1971-1980': pd.DataFrame(s_c_AB_df).loc[:,'1971':'1980'].sum(axis=1), \n",
    "          '1981-1990': pd.DataFrame(s_c_AB_df).loc[:,'1981':'1990'].sum(axis=1), \n",
    "          '1991-2000': pd.DataFrame(s_c_AB_df).loc[:,'1991':'2000'].sum(axis=1), \n",
    "          '2001-2010': pd.DataFrame(s_c_AB_df).loc[:,'2001':'2010'].sum(axis=1), \n",
    "          'post-2010': pd.DataFrame(s_c_AB_df).loc[:,'2011':'2050'].sum(axis=1)}\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total stock (s_total), total stock by cohort (s_c_total)\n",
    "\n",
    "Calculate stock_changes by inflow - outflow for each type and aggregated\n",
    "\n",
    "Calculate total inflows and outflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_total = s_SFH_df + s_TH_df + s_AB_df\n",
    "\n",
    "total_stock_by_tabula_cohort = SFH_stock_by_tabula_cohort + TH_stock_by_tabula_cohort + AB_stock_by_tabula_cohort\n",
    "\n",
    "stock_change_SFH = i_SFH_df - pd.DataFrame(o_SFH_df.sum(axis=1))\n",
    "stock_change_TH = i_TH_df - pd.DataFrame(o_TH_df.sum(axis=1))\n",
    "stock_change_AB = i_AB_df - pd.DataFrame(o_AB_df.sum(axis=1))\n",
    "\n",
    "stock_change_total = stock_change_SFH + stock_change_TH + stock_change_AB\n",
    "\n",
    "i_total = i_SFH_df + i_TH_df + i_AB_df\n",
    "\n",
    "o_total = o_SFH_df + o_TH_df + o_AB_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert number of dwellings into floor area by DSM cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_UFA_c_SFH = s_c_SFH_df @ np.diag(UFApD['UFApD SFH'])\n",
    "s_UFA_c_SFH = pd.DataFrame(s_UFA_c_SFH)\n",
    "s_UFA_c_SFH.columns = np.arange(1600, 2051)\n",
    "\n",
    "s_UFA_c_TH = s_c_TH_df @ np.diag(UFApD['UFApD TH'])\n",
    "s_UFA_c_TH = pd.DataFrame(s_UFA_c_TH)\n",
    "s_UFA_c_TH.columns = np.arange(1600, 2051)\n",
    "\n",
    "s_UFA_c_AB = s_c_AB_df @ np.diag(UFApD['UFApD AB'])\n",
    "s_UFA_c_AB = pd.DataFrame(s_UFA_c_AB)\n",
    "s_UFA_c_AB.columns = np.arange(1600, 2051)\n",
    "\n",
    "i_SFH_UFA = i_SFH_df.mul(UFApD['UFApD SFH'].values, axis=0)\n",
    "i_SFH_UFA = pd.DataFrame(i_SFH_UFA)\n",
    "\n",
    "\n",
    "o_SFH_UFA = o_SFH_df @ np.diag(UFApD['UFApD SFH'])\n",
    "o_SFH_UFA = pd.DataFrame(o_SFH_UFA)\n",
    "o_SFH_UFA.columns = np.arange(1600, 2051)\n",
    "\n",
    "i_TH_UFA = i_TH_df.mul(UFApD['UFApD TH'].values, axis=0)\n",
    "i_TH_UFA = pd.DataFrame(i_TH_UFA)\n",
    "\n",
    "\n",
    "o_TH_UFA = o_TH_df @ np.diag(UFApD['UFApD TH'])\n",
    "o_TH_UFA = pd.DataFrame(o_TH_UFA)\n",
    "o_TH_UFA.columns = np.arange(1600, 2051)\n",
    "\n",
    "i_AB_UFA = i_AB_df.mul(UFApD['UFApD AB'].values, axis=0)\n",
    "i_AB_UFA = pd.DataFrame(i_AB_UFA)\n",
    "\n",
    "o_AB_UFA = o_AB_df @ np.diag(UFApD['UFApD AB'])\n",
    "o_AB_UFA = pd.DataFrame(o_AB_UFA)\n",
    "o_AB_UFA.columns = np.arange(1600, 2051)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make s_c_UFA arrays into dataframes for easier use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1600</th>\n",
       "      <th>1601</th>\n",
       "      <th>1602</th>\n",
       "      <th>1603</th>\n",
       "      <th>1604</th>\n",
       "      <th>1605</th>\n",
       "      <th>1606</th>\n",
       "      <th>1607</th>\n",
       "      <th>1608</th>\n",
       "      <th>1609</th>\n",
       "      <th>...</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>2048</th>\n",
       "      <th>2049</th>\n",
       "      <th>2050</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>1.667922e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>1.667862e+06</td>\n",
       "      <td>2.008846e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>1.667798e+06</td>\n",
       "      <td>2.008774e+03</td>\n",
       "      <td>2.040886e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>1.667729e+06</td>\n",
       "      <td>2.008696e+03</td>\n",
       "      <td>2.040813e+03</td>\n",
       "      <td>2.073625e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>1.667654e+06</td>\n",
       "      <td>2.008613e+03</td>\n",
       "      <td>2.040734e+03</td>\n",
       "      <td>2.073551e+03</td>\n",
       "      <td>2.107088e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>4.678954e-05</td>\n",
       "      <td>6.535782e-08</td>\n",
       "      <td>7.697307e-08</td>\n",
       "      <td>9.061719e-08</td>\n",
       "      <td>1.066386e-07</td>\n",
       "      <td>1.254445e-07</td>\n",
       "      <td>1.475107e-07</td>\n",
       "      <td>1.733932e-07</td>\n",
       "      <td>2.037411e-07</td>\n",
       "      <td>2.393119e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>661782.765637</td>\n",
       "      <td>665146.285509</td>\n",
       "      <td>668613.485263</td>\n",
       "      <td>672187.270753</td>\n",
       "      <td>675870.177385</td>\n",
       "      <td>679664.343392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>4.032377e-05</td>\n",
       "      <td>5.635323e-08</td>\n",
       "      <td>6.640013e-08</td>\n",
       "      <td>7.820771e-08</td>\n",
       "      <td>9.207932e-08</td>\n",
       "      <td>1.083698e-07</td>\n",
       "      <td>1.274938e-07</td>\n",
       "      <td>1.499361e-07</td>\n",
       "      <td>1.762631e-07</td>\n",
       "      <td>2.071361e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>661782.519516</td>\n",
       "      <td>665146.092837</td>\n",
       "      <td>668613.334861</td>\n",
       "      <td>672187.153680</td>\n",
       "      <td>675870.086511</td>\n",
       "      <td>679664.273052</td>\n",
       "      <td>683571.429116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>3.473478e-05</td>\n",
       "      <td>4.856587e-08</td>\n",
       "      <td>5.725194e-08</td>\n",
       "      <td>6.746518e-08</td>\n",
       "      <td>7.946961e-08</td>\n",
       "      <td>9.357415e-08</td>\n",
       "      <td>1.101401e-07</td>\n",
       "      <td>1.295900e-07</td>\n",
       "      <td>1.524177e-07</td>\n",
       "      <td>1.792002e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>661782.206527</td>\n",
       "      <td>665145.847094</td>\n",
       "      <td>668613.142464</td>\n",
       "      <td>672187.003475</td>\n",
       "      <td>675869.969575</td>\n",
       "      <td>679664.182273</td>\n",
       "      <td>683571.358840</td>\n",
       "      <td>687592.766470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>2.990605e-05</td>\n",
       "      <td>4.183451e-08</td>\n",
       "      <td>4.934039e-08</td>\n",
       "      <td>5.817025e-08</td>\n",
       "      <td>6.855375e-08</td>\n",
       "      <td>8.075973e-08</td>\n",
       "      <td>9.510282e-08</td>\n",
       "      <td>1.119511e-07</td>\n",
       "      <td>1.317349e-07</td>\n",
       "      <td>1.549575e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>661781.809564</td>\n",
       "      <td>665145.534499</td>\n",
       "      <td>668612.897006</td>\n",
       "      <td>672186.811279</td>\n",
       "      <td>675869.819509</td>\n",
       "      <td>679664.065431</td>\n",
       "      <td>683571.268121</td>\n",
       "      <td>687592.696230</td>\n",
       "      <td>691729.142874</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>2.573621e-05</td>\n",
       "      <td>3.601879e-08</td>\n",
       "      <td>4.250167e-08</td>\n",
       "      <td>5.013180e-08</td>\n",
       "      <td>5.910884e-08</td>\n",
       "      <td>6.966666e-08</td>\n",
       "      <td>8.207905e-08</td>\n",
       "      <td>9.666649e-08</td>\n",
       "      <td>1.138039e-07</td>\n",
       "      <td>1.339300e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>661781.307443</td>\n",
       "      <td>665145.137930</td>\n",
       "      <td>668612.584690</td>\n",
       "      <td>672186.566013</td>\n",
       "      <td>675869.627442</td>\n",
       "      <td>679663.915447</td>\n",
       "      <td>683571.151327</td>\n",
       "      <td>687592.605537</td>\n",
       "      <td>691729.072645</td>\n",
       "      <td>695980.847153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows Ã— 451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1600          1601          1602          1603          1604  \\\n",
       "Year                                                                         \n",
       "1600  1.667922e+06  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1601  1.667862e+06  2.008846e+03  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1602  1.667798e+06  2.008774e+03  2.040886e+03  0.000000e+00  0.000000e+00   \n",
       "1603  1.667729e+06  2.008696e+03  2.040813e+03  2.073625e+03  0.000000e+00   \n",
       "1604  1.667654e+06  2.008613e+03  2.040734e+03  2.073551e+03  2.107088e+03   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2046  4.678954e-05  6.535782e-08  7.697307e-08  9.061719e-08  1.066386e-07   \n",
       "2047  4.032377e-05  5.635323e-08  6.640013e-08  7.820771e-08  9.207932e-08   \n",
       "2048  3.473478e-05  4.856587e-08  5.725194e-08  6.746518e-08  7.946961e-08   \n",
       "2049  2.990605e-05  4.183451e-08  4.934039e-08  5.817025e-08  6.855375e-08   \n",
       "2050  2.573621e-05  3.601879e-08  4.250167e-08  5.013180e-08  5.910884e-08   \n",
       "\n",
       "              1605          1606          1607          1608          1609  \\\n",
       "Year                                                                         \n",
       "1600  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1601  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1602  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1603  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "1604  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2046  1.254445e-07  1.475107e-07  1.733932e-07  2.037411e-07  2.393119e-07   \n",
       "2047  1.083698e-07  1.274938e-07  1.499361e-07  1.762631e-07  2.071361e-07   \n",
       "2048  9.357415e-08  1.101401e-07  1.295900e-07  1.524177e-07  1.792002e-07   \n",
       "2049  8.075973e-08  9.510282e-08  1.119511e-07  1.317349e-07  1.549575e-07   \n",
       "2050  6.966666e-08  8.207905e-08  9.666649e-08  1.138039e-07  1.339300e-07   \n",
       "\n",
       "      ...           2041           2042           2043           2044  \\\n",
       "Year  ...                                                               \n",
       "1600  ...       0.000000       0.000000       0.000000       0.000000   \n",
       "1601  ...       0.000000       0.000000       0.000000       0.000000   \n",
       "1602  ...       0.000000       0.000000       0.000000       0.000000   \n",
       "1603  ...       0.000000       0.000000       0.000000       0.000000   \n",
       "1604  ...       0.000000       0.000000       0.000000       0.000000   \n",
       "...   ...            ...            ...            ...            ...   \n",
       "2046  ...  661782.765637  665146.285509  668613.485263  672187.270753   \n",
       "2047  ...  661782.519516  665146.092837  668613.334861  672187.153680   \n",
       "2048  ...  661782.206527  665145.847094  668613.142464  672187.003475   \n",
       "2049  ...  661781.809564  665145.534499  668612.897006  672186.811279   \n",
       "2050  ...  661781.307443  665145.137930  668612.584690  672186.566013   \n",
       "\n",
       "               2045           2046           2047           2048  \\\n",
       "Year                                                               \n",
       "1600       0.000000       0.000000       0.000000       0.000000   \n",
       "1601       0.000000       0.000000       0.000000       0.000000   \n",
       "1602       0.000000       0.000000       0.000000       0.000000   \n",
       "1603       0.000000       0.000000       0.000000       0.000000   \n",
       "1604       0.000000       0.000000       0.000000       0.000000   \n",
       "...             ...            ...            ...            ...   \n",
       "2046  675870.177385  679664.343392       0.000000       0.000000   \n",
       "2047  675870.086511  679664.273052  683571.429116       0.000000   \n",
       "2048  675869.969575  679664.182273  683571.358840  687592.766470   \n",
       "2049  675869.819509  679664.065431  683571.268121  687592.696230   \n",
       "2050  675869.627442  679663.915447  683571.151327  687592.605537   \n",
       "\n",
       "               2049           2050  \n",
       "Year                                \n",
       "1600       0.000000       0.000000  \n",
       "1601       0.000000       0.000000  \n",
       "1602       0.000000       0.000000  \n",
       "1603       0.000000       0.000000  \n",
       "1604       0.000000       0.000000  \n",
       "...             ...            ...  \n",
       "2046       0.000000       0.000000  \n",
       "2047       0.000000       0.000000  \n",
       "2048       0.000000       0.000000  \n",
       "2049  691729.142874       0.000000  \n",
       "2050  691729.072645  695980.847153  \n",
       "\n",
       "[451 rows x 451 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UFApD.drop_duplicates(inplace=True)\n",
    "\n",
    "s_UFA_c_SFH_df = pd.DataFrame(s_UFA_c_SFH)\n",
    "s_UFA_c_SFH_df = s_UFA_c_SFH_df.set_index(UFApD.index)\n",
    "s_UFA_c_SFH_df.columns = np.arange(1600, 2051)\n",
    "s_UFA_c_SFH_df\n",
    "\n",
    "s_UFA_c_TH_df = pd.DataFrame(s_UFA_c_TH)\n",
    "s_UFA_c_TH_df = s_UFA_c_TH_df.set_index(UFApD.index)\n",
    "s_UFA_c_TH_df.columns = np.arange(1600, 2051)\n",
    "s_UFA_c_TH_df\n",
    "\n",
    "s_UFA_c_AB_df = pd.DataFrame(s_UFA_c_AB)\n",
    "s_UFA_c_AB_df = s_UFA_c_AB_df.set_index(UFApD.index)\n",
    "s_UFA_c_AB_df.columns = np.arange(1600, 2051)\n",
    "s_UFA_c_AB_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate s_c dataframes into the cohorts from tabula for each type for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "SFH_UFA_stock_by_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'1600':'1955'].sum(axis=1), \n",
    "          '1956-1970': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'1956':'1970'].sum(axis=1), \n",
    "          '1971-1980': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'1971':'1980'].sum(axis=1), \n",
    "          '1981-1990': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'1981':'1990'].sum(axis=1), \n",
    "          '1991-2000': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'1991':'2000'].sum(axis=1), \n",
    "          '2001-2010': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'2001':'2010'].sum(axis=1), \n",
    "          'post-2010': pd.DataFrame(s_UFA_c_SFH_df).loc[:,'2011':'2050'].sum(axis=1)}\n",
    "          )\n",
    "\n",
    "TH_UFA_stock_by_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(s_UFA_c_TH_df).loc[:,'1600':'1955'].sum(axis=1), \n",
    "          '1956-1970': pd.DataFrame(s_UFA_c_TH_df).loc[:,'1956':'1970'].sum(axis=1), \n",
    "          '1971-1980': pd.DataFrame(s_UFA_c_TH_df).loc[:,'1971':'1980'].sum(axis=1), \n",
    "          '1981-1990': pd.DataFrame(s_UFA_c_TH_df).loc[:,'1981':'1990'].sum(axis=1), \n",
    "          '1991-2000': pd.DataFrame(s_UFA_c_TH_df).loc[:,'1991':'2000'].sum(axis=1), \n",
    "          '2001-2010': pd.DataFrame(s_UFA_c_TH_df).loc[:,'2001':'2010'].sum(axis=1), \n",
    "          'post-2010': pd.DataFrame(s_UFA_c_TH_df).loc[:,'2011':'2050'].sum(axis=1)}\n",
    "          )\n",
    "\n",
    "AB_UFA_stock_by_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(s_UFA_c_AB_df).loc[:,'1600':'1955'].sum(axis=1), \n",
    "          '1956-1970': pd.DataFrame(s_UFA_c_AB_df).loc[:,'1956':'1970'].sum(axis=1), \n",
    "          '1971-1980': pd.DataFrame(s_UFA_c_AB_df).loc[:,'1971':'1980'].sum(axis=1), \n",
    "          '1981-1990': pd.DataFrame(s_UFA_c_AB_df).loc[:,'1981':'1990'].sum(axis=1), \n",
    "          '1991-2000': pd.DataFrame(s_UFA_c_AB_df).loc[:,'1991':'2000'].sum(axis=1), \n",
    "          '2001-2010': pd.DataFrame(s_UFA_c_AB_df).loc[:,'2001':'2010'].sum(axis=1), \n",
    "          'post-2010': pd.DataFrame(s_UFA_c_AB_df).loc[:,'2011':'2050'].sum(axis=1)}\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total stock (s_total), total stock by cohort (s_c_total)\n",
    "\n",
    "Calculate stock_changes by inflow - outflow for each type and aggregated\n",
    "\n",
    "Calculate total inflows and outflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_UFA_total = s_UFA_c_SFH.sum(axis=1) + s_UFA_c_TH.sum(axis=1) + s_UFA_c_AB.sum(axis=1)\n",
    "\n",
    "total_stock_UFA_by_tabula_cohort = SFH_UFA_stock_by_tabula_cohort + TH_UFA_stock_by_tabula_cohort + AB_UFA_stock_by_tabula_cohort\n",
    "\n",
    "stock_change_SFH_UFA = i_SFH_UFA - pd.DataFrame(o_SFH_UFA.sum(axis=1))\n",
    "stock_change_TH_UFA = i_TH_UFA - pd.DataFrame(o_TH_UFA.sum(axis=1))\n",
    "stock_change_AB_UFA = i_AB_UFA - pd.DataFrame(o_AB_UFA.sum(axis=1))\n",
    "\n",
    "stock_change_total_UFA = stock_change_SFH_UFA + stock_change_TH_UFA + stock_change_AB_UFA\n",
    "\n",
    "i_total_UFA = i_SFH_UFA + i_TH_UFA + i_AB_UFA\n",
    "\n",
    "o_total_UFA = o_SFH_UFA + o_TH_UFA + o_AB_UFA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that calculates energy use for SFH, original renovation level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_use_calculation_SFH(stock_c_UFA):\n",
    "    energy_use_matrix = pd.DataFrame()\n",
    "    for year in stock_c_UFA.columns:\n",
    "        if int(year) <= 1955:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('pre 1955' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1956 and int(year) <= 1970:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('1956-70' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1971 and int(year) <= 1980:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('1971-80' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1981 and int(year) <= 1990:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('1981-90' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1991 and int(year) <= 2000:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('1991-2000' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 2001 and int(year) <= 2010:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('2001-2010' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 2011:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_SFH.loc[:, year],energy_intensity.loc[('2011-' , 'SFH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "    return energy_use_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function that spits out energy use of SFH by DSM cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_matrix_SFH = energy_use_calculation_SFH(s_UFA_c_SFH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate vector of energy use for SFH (not by cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_vector_SFH = energy_use_matrix_SFH.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that calculates energy use for TH, original renovation level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_use_calculation_TH(stock_c_UFA):\n",
    "    energy_use_matrix = pd.DataFrame()\n",
    "    for year in stock_c_UFA.columns:\n",
    "        if int(year) <= 1955:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('pre 1955' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1956 and int(year) <= 1970:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('1956-70' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1971 and int(year) <= 1980:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('1971-80' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1981 and int(year) <= 1990:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('1981-90' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1991 and int(year) <= 2000:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('1991-2000' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 2001 and int(year) <= 2010:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('2001-2010' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 2011:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_TH.loc[:, year],energy_intensity.loc[('2011-' , 'TH', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "    return energy_use_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function that spits out energy use of TH by DSM cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_matrix_TH = energy_use_calculation_TH(s_UFA_c_TH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate vector of energy use for TH (not by cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_vector_TH = energy_use_matrix_TH.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that calculates energy use for AB, original renovation level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_use_calculation_AB(stock_c_UFA):\n",
    "    energy_use_matrix = pd.DataFrame()\n",
    "    for year in stock_c_UFA.columns:\n",
    "        if int(year) <= 1955:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('pre 1955' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1956 and int(year) <= 1970:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('1956-70' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1971 and int(year) <= 1980:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('1971-80' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1981 and int(year) <= 1990:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('1981-90' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 1991 and int(year) <= 2000:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('1991-2000' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 2001 and int(year) <= 2010:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('2001-2010' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "        elif int(year) >= 2011:\n",
    "            iteration = pd.DataFrame(np.multiply(s_UFA_c_AB.loc[:, year],energy_intensity.loc[('2011-' , 'AB', 'OG'),'Energy intensity  (kWh/m2a)']))\n",
    "            energy_use_matrix = pd.concat([energy_use_matrix, iteration], axis=1)\n",
    "    return energy_use_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run function that spits out energy use of AB by DSM cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_matrix_AB = energy_use_calculation_AB(s_UFA_c_AB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate vector of energy use for AB (not by cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_vector_AB = energy_use_matrix_AB.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total energy use matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_matrix_total = energy_use_matrix_SFH + energy_use_matrix_TH + energy_use_matrix_AB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate energy use vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SFH</th>\n",
       "      <th>TH</th>\n",
       "      <th>AB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>2.897224e+09</td>\n",
       "      <td>5.720316e+08</td>\n",
       "      <td>3.269127e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>2.900607e+09</td>\n",
       "      <td>5.727000e+08</td>\n",
       "      <td>3.272947e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>2.904035e+09</td>\n",
       "      <td>5.733777e+08</td>\n",
       "      <td>3.276821e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>2.907508e+09</td>\n",
       "      <td>5.740649e+08</td>\n",
       "      <td>3.280749e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>2.911027e+09</td>\n",
       "      <td>5.747616e+08</td>\n",
       "      <td>3.284733e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>4.772425e+10</td>\n",
       "      <td>1.053728e+10</td>\n",
       "      <td>7.926877e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>4.761917e+10</td>\n",
       "      <td>1.051316e+10</td>\n",
       "      <td>7.930716e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>4.750700e+10</td>\n",
       "      <td>1.048777e+10</td>\n",
       "      <td>7.933667e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>4.738770e+10</td>\n",
       "      <td>1.046111e+10</td>\n",
       "      <td>7.935723e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>4.726119e+10</td>\n",
       "      <td>1.043318e+10</td>\n",
       "      <td>7.936883e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               SFH            TH            AB\n",
       "Year                                          \n",
       "1600  2.897224e+09  5.720316e+08  3.269127e+08\n",
       "1601  2.900607e+09  5.727000e+08  3.272947e+08\n",
       "1602  2.904035e+09  5.733777e+08  3.276821e+08\n",
       "1603  2.907508e+09  5.740649e+08  3.280749e+08\n",
       "1604  2.911027e+09  5.747616e+08  3.284733e+08\n",
       "...            ...           ...           ...\n",
       "2046  4.772425e+10  1.053728e+10  7.926877e+09\n",
       "2047  4.761917e+10  1.051316e+10  7.930716e+09\n",
       "2048  4.750700e+10  1.048777e+10  7.933667e+09\n",
       "2049  4.738770e+10  1.046111e+10  7.935723e+09\n",
       "2050  4.726119e+10  1.043318e+10  7.936883e+09\n",
       "\n",
       "[451 rows x 3 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_use_vectors_concatenated = pd.concat([energy_use_vector_SFH, energy_use_vector_TH, energy_use_vector_AB], axis=1)\n",
    "energy_use_vectors_concatenated = energy_use_vectors_concatenated.rename(columns={0: 'SFH', 1: 'TH', 2: 'AB'})\n",
    "\n",
    "#energy_use_vectors_concatenated = pd.concat([energy_use_vectors_concatenat1, energy_use_vector_AB], axis=1)\n",
    "\n",
    "energy_use_vectors_concatenated "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put energy use matrix into tabula cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_use_matrix_total_tabula_cohort = pd.DataFrame(\n",
    "    data={'pre-1955': pd.DataFrame(energy_use_matrix_total).loc[:,'1600':'1955'].sum(axis=1)/1000000000, \n",
    "          '1956-1970': pd.DataFrame(energy_use_matrix_total).loc[:,'1956':'1970'].sum(axis=1)/1000000000, \n",
    "          '1971-1980': pd.DataFrame(energy_use_matrix_total).loc[:,'1971':'1980'].sum(axis=1)/1000000000, \n",
    "          '1981-1990': pd.DataFrame(energy_use_matrix_total).loc[:,'1981':'1990'].sum(axis=1)/1000000000, \n",
    "          '1991-2000': pd.DataFrame(energy_use_matrix_total).loc[:,'1991':'2000'].sum(axis=1)/1000000000, \n",
    "          '2001-2010': pd.DataFrame(energy_use_matrix_total).loc[:,'2001':'2010'].sum(axis=1)/1000000000, \n",
    "          'post-2010': pd.DataFrame(energy_use_matrix_total).loc[:,'2011':'2050'].sum(axis=1)/1000000000}\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate total energy use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_energy_use = energy_use_vector_SFH + energy_use_vector_TH + energy_use_vector_AB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_SFH_df.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/s_SFH.xlsx')\n",
    "\n",
    "s_TH_df.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/s_TH.xlsx')\n",
    "\n",
    "s_AB_df.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/s_AB.xlsx')\n",
    "\n",
    "SFH_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/s_c_SFH.xlsx')\n",
    "\n",
    "TH_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/s_c_TH.xlsx')\n",
    "\n",
    "AB_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/s_c_AB.xlsx')\n",
    "\n",
    "stock_change_total.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/s_delta_total.xlsx')\n",
    "\n",
    "total_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/s_c_total.xlsx')\n",
    "\n",
    "pd.DataFrame(i_SFH).to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/i_SFH.xlsx')\n",
    "\n",
    "pd.DataFrame(i_TH).to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/i_TH.xlsx')\n",
    "\n",
    "pd.DataFrame(i_AB).to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/i_AB.xlsx')\n",
    "\n",
    "o_total.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/o_total.xlsx')\n",
    "\n",
    "i_total.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/i_total.xlsx')\n",
    "\n",
    "s_UFA_c_SFH_df.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/s_UFA_c_SFH.xlsx')\n",
    "\n",
    "s_UFA_c_TH_df.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/s_UFA_c_TH.xlsx')\n",
    "\n",
    "s_UFA_c_AB_df.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/s_UFA_c_AB.xlsx')\n",
    "\n",
    "SFH_UFA_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/s_UFA_tabula_SFH.xlsx')\n",
    "\n",
    "TH_UFA_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/s_UFA_tabula_TH.xlsx')\n",
    "\n",
    "AB_UFA_stock_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/s_UFA_tabula_AB.xlsx')\n",
    "\n",
    "stock_change_total_UFA.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/s_delta_total_UFA.xlsx')\n",
    "\n",
    "total_stock_UFA_by_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/s_UFA_tabula_total.xlsx')\n",
    "\n",
    "i_SFH_UFA.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/i_SFH_UFA.xlsx')\n",
    "\n",
    "i_TH_UFA.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/i_TH_UFA.xlsx')\n",
    "\n",
    "i_AB_UFA.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/i_AB_UFA.xlsx')\n",
    "\n",
    "o_total_UFA.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/o_total_UFA.xlsx')\n",
    "\n",
    "i_total_UFA.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/i_total_UFA.xlsx')\n",
    "\n",
    "energy_use_vector_SFH.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/energy_use_vector_SFH.xlsx')\n",
    "\n",
    "energy_use_vector_TH.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/energy_use_vector_TH.xlsx')\n",
    "\n",
    "energy_use_vector_AB.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/energy_use_vector_AB.xlsx')\n",
    "\n",
    "energy_use_matrix_total_tabula_cohort.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/energy_use_matrix_total_tabula.xlsx')\n",
    "\n",
    "total_energy_use.to_excel(directory_path / \n",
    "                 'data/model_outputs_baseline/total_energy_use.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TEP4221",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
